#Logger enabled
#input {
#  file {
#    start_position => "beginning"
#    path => "/var/seamless/log/order-management-system/om-data.dump"
#    sincedb_path => "/var/seamless/log/logstash/sincedb_order_data_lake.log"
#  }
#}

#Filebeat pipeline configuration
input
{
      pipeline
      {
            address => orderDataLakePipeline
      }
}

filter
{
  json
  {
    source => "message"
    skip_on_invalid_json => true
  }

  date
  {
    match => ["timestamp", "yyyy-MM-dd HH:mm:ss"]

    # IF LOGSTASH SERVER IS ON BANGLADESH TIMEZONE THEN ENABLE BELOW LINE
    #timezone => "Asia/Dhaka"

    # IF YOU ARE NOT SURE ABOUT THE TIMEZONE OF THE LOGSTASH SERVER THEN ENABLE BELOW LINE
    timezone => "UTC"

    target => "timestamp"
  }

   prune
     {
         blacklist_names => ["^log$","^tags$","^agent$","^message$","^path$","^@version$","^host$","^ecs$","^input$","^cloud$","^event$"]
     }

  if "_jsonparsefailure" not in [tags]
  {

    if ([oms.orderType] == "ISO" or [oms.orderType] == "PSEUDO_ORDER") and [eventName] == "RAISE_ORDER" and [oms.seller.sellerType] == "DIST" and ([oms.buyer.buyerType] == "RET" or [oms.buyer.buyerType] == "GPCF") and [oms.resultCode] == 0
    {
        if [oms.invoices]
        {
            ruby {
                code => '
                    begin
                        # Extract product codes from invoice entries only
                        product_codes = []

                        # Get codes from invoice entries
                        invoices = event.get("[oms.invoices]")
                        if invoices && invoices.is_a?(Array)
                            invoices.each do |invoice|
                                invoice_entries = invoice["invoice.invoiceEntries"]
                                if invoice_entries && invoice_entries.is_a?(Array)
                                    invoice_entries.each { |entry|
                                        product_codes << entry["productCode"] if entry["productCode"]
                                    }
                                end
                            end
                        end

                        # Remove duplicates and set for JDBC lookup
                        product_codes = product_codes.compact.uniq
                        event.set("product_codes_array", product_codes)
                    rescue => e
                        logger.error("Error extracting product codes: #{e.message}")
                    end
                '
            }

            jdbc_streaming {
                jdbc_driver_library => "/opt/seamless/conf/logstash/jar/mariadb-java-client-2.6.2.jar"
                jdbc_driver_class => "org.mariadb.jdbc.Driver"
                jdbc_connection_string => "jdbc:mariadb://{{ .Values.DB_HOST__pms }}:{{ .Values.DB_PORT__pms }}/pms"
                jdbc_user => {{ .Values.DB_HOST__password }}
                jdbc_password => {{ .Values.DB_HOST__password }}
                statement => "CALL GetProductsByCodes(?)"
                prepared_statement_bind_values => "%{product_codes_array}"
                target => "product_hierarchy"
		        prepared_statement_name => "product_hierarchy_lookup"
                use_prepared_statements => true
            }

            ruby {
                code => '
                    begin
                        product_hierarchy = event.get("product_hierarchy")

                        if product_hierarchy && product_hierarchy.is_a?(Array)
                            # Enrich invoice entries only
                            invoices = event.get("[oms.invoices]")
                            if invoices && invoices.is_a?(Array)
                                invoices.each do |invoice|
                                    invoice_entries = invoice["invoice.invoiceEntries"]
                                    if invoice_entries && invoice_entries.is_a?(Array)
                                        invoice_entries.each do |entry|
                                            if entry["productCode"]
                                                # Find matching product in hierarchy
                                                matching_product = product_hierarchy.find { |p| p["code"] == entry["productCode"] }

                                                if matching_product
                                                    # Add hierarchy fields to invoice entry
                                                    entry["product_id"] = matching_product["product_id"]
                                                    entry["product_head_id"] = matching_product["product_head_id"]
                                                    entry["product_group_id"] = matching_product["product_group_id"]
                                                    entry["product_group_type"] = matching_product["product_group_type"]
                                                end
                                            end
                                        end
                                        # Update invoice entries
                                        invoice["invoice.invoiceEntries"] = invoice_entries
                                    end
                                end
                                # Update invoices array
                                event.set("[oms.invoices]", invoices)
                            end

                            # Remove product_hierarchy
                            event.remove("product_hierarchy")
                        end
                    rescue => e
                        logger.error("Error enriching invoice entries with product hierarchy: #{e.message}")
                    end
                '
            }
        }

        # Process oms.items to enrich invoice.invoiceEntries with serials or quantity
        if [oms.items]
        {
            ruby {
                code => '
                    begin
                        items = event.get("[oms.items]")
                        invoices = event.get("[oms.invoices]")

                        if items && items.is_a?(Array) && invoices && invoices.is_a?(Array)
                            # Create a map of invoice entries by productCode for quick lookup
                            invoice_entries_map = {}
                            invoices.each_with_index do |invoice, invoice_index|
                                invoice_entries = invoice["invoice.invoiceEntries"]
                                if invoice_entries && invoice_entries.is_a?(Array)
                                    invoice_entries.each_with_index do |entry, entry_index|
                                        product_code = entry["productCode"]
                                        if product_code
                                            invoice_entries_map[product_code] = {
                                                "invoice_index" => invoice_index,
                                                "entry_index" => entry_index,
                                                "entry" => entry
                                            }
                                        end
                                    end
                                end
                            end

                            # Process each item in oms.items
                            items.each do |item|
                                product_code = item["productCode"]
                                next unless product_code

                                # Find matching invoice entry
                                invoice_entry_info = invoice_entries_map[product_code]
                                next unless invoice_entry_info

                                serials = item["serials"]
                                ranges = item["ranges"]
                                quantity = item["quantity"]

                                # Condition 1: serials array exists and is non-empty
                                if serials && serials.is_a?(Array) && !serials.empty?
                                    # Add serials to invoiceEntryProperties
                                    invoice_entry = invoice_entry_info["entry"]
                                    invoice_entry["invoiceEntryProperties"] ||= {}
                                    invoice_entry["invoiceEntryProperties"]["serials"] = serials.join(",")
                                    invoice_entry["invoiceEntryProperties"]["quantity"] = serials.length.to_s

                                # Condition 2: serials empty/missing but ranges exists and is non-empty
                                elsif ranges && ranges.is_a?(Array) && !ranges.empty?
                                    range_info = ranges.first
                                    if range_info && range_info["startSerial"] && range_info["endSerial"]
                                        start_serial = range_info["startSerial"].to_i
                                        end_serial = range_info["endSerial"].to_i

                                        # Generate serials using arithmetic progression
                                        generated_serials = []
                                        if start_serial <= end_serial
                                            (start_serial..end_serial).each do |serial_num|
                                                generated_serials << serial_num.to_s
                                            end
                                        end

                                        # Add generated serials to invoiceEntryProperties
                                        if !generated_serials.empty?
                                            invoice_entry = invoice_entry_info["entry"]
                                            invoice_entry["invoiceEntryProperties"] ||= {}
                                            invoice_entry["invoiceEntryProperties"]["serials"] = generated_serials.join(",")
                                            invoice_entry["invoiceEntryProperties"]["quantity"] = generated_serials.length.to_s
                                        end
                                    end

                                # Condition 3: both serials and ranges are empty/missing
                                else
                                    # Add quantity to invoiceEntryProperties
                                    if quantity
                                        invoice_entry = invoice_entry_info["entry"]
                                        invoice_entry["invoiceEntryProperties"] ||= {}
                                        invoice_entry["invoiceEntryProperties"]["serials"] = ""
                                        invoice_entry["invoiceEntryProperties"]["quantity"] = quantity
                                    end
                                end
                            end

                            # Update the invoices back to event
                            event.set("[oms.invoices]", invoices)
                        end
                    rescue => e
                        logger.error("Error processing oms.items for invoice enrichment: #{e.message}")
                    end
                '
            }
        }

        # Fetch sender employee group information if employeeId is present and valid
        if [oms.sender.employeeId] and [oms.sender.employeeId] != "" and [oms.sender.employeeId] != "N/A"
        {
            jdbc_streaming {
                jdbc_driver_library => "/opt/seamless/conf/logstash/jar/mariadb-java-client-2.6.2.jar"
                jdbc_driver_class => "org.mariadb.jdbc.Driver"
                jdbc_connection_string => "jdbc:mariadb://{{ .Values.DB_HOST__groupmanagementsystem }}:{{ .Values.DB_PORT__groupmanagementsystem }}/groupmanagementsystem"
                jdbc_user => {{ .Values.DB_HOST__password }}
                jdbc_password => {{ .Values.DB_HOST__password }}
                statement => "SELECT g.name AS group_name, g.code AS group_code, a.name AS admin_name FROM admin a INNER JOIN group_admin ga ON a.admin_id = ga.admin_id INNER JOIN `group` g ON ga.group_id = g.group_id WHERE a.user_id = ? AND ga.status = 'ACTIVE' AND g.status = 'ACTIVE'"
                prepared_statement_bind_values => "%{[oms.sender.employeeId]}"
                target => "employee_group_info"
                prepared_statement_name => "employee_group_lookup"
                use_prepared_statements => true
            }

            ruby {
                code => '
                    begin
                        employee_group_info = event.get("employee_group_info")

                        if employee_group_info && employee_group_info.is_a?(Array) && !employee_group_info.empty?
                            group_info = employee_group_info.first
                            event.set("oms.sender.routeName", group_info["group_name"])
                            event.set("oms.sender.routeCode", group_info["group_code"])
                            event.set("oms.sender.employeeName", group_info["admin_name"])
                        end

                        # Remove the temporary field
                        event.remove("employee_group_info")
                    rescue => e
                        logger.error("Error processing employee group information: #{e.message}")
                    end
                '
            }
        }

        # Fallback: Fetch employee name from commission_receivers if not already present
        if ![oms.sender.employeeName] and [oms.sender.employeeId] and [oms.sender.employeeId] != "" and [oms.sender.employeeId] != "N/A"
        {
            jdbc_streaming {
                jdbc_driver_library => "/opt/seamless/conf/logstash/jar/mariadb-java-client-2.6.2.jar"
                jdbc_driver_class => "org.mariadb.jdbc.Driver"
                jdbc_connection_string => "jdbc:mariadb://{{ .Values.DB_HOST__Refill }}:{{ .Values.DB_PORT__Refill }}/Refill"
                jdbc_user => {{ .Values.DB_HOST__password }}
                jdbc_password => {{ .Values.DB_HOST__password }}
                statement => "SELECT name FROM commission_receivers WHERE tag = ?"
                prepared_statement_bind_values => "%{[oms.sender.employeeId]}"
                target => "employee_name_info"
                prepared_statement_name => "employee_name_lookup"
                use_prepared_statements => true
            }

            ruby {
                code => '
                    begin
                        employee_name_info = event.get("employee_name_info")

                        if employee_name_info && employee_name_info.is_a?(Array) && !employee_name_info.empty?
                            name_info = employee_name_info.first
                            event.set("oms.sender.employeeName", name_info["name"])
                        end

                        # Remove the temporary field
                        event.remove("employee_name_info")
                    rescue => e
                        logger.error("Error processing employee name from commission_receivers: #{e.message}")
                    end
                '
            }
        }

        # Fetch buyer partner properties from reseller_dynamic_data
        if [oms.buyer.id]
        {
            jdbc_streaming {
                jdbc_driver_library => "/opt/seamless/conf/logstash/jar/mariadb-java-client-2.6.2.jar"
                jdbc_driver_class => "org.mariadb.jdbc.Driver"
                jdbc_connection_string => "jdbc:mariadb://{{ .Values.DB_HOST__Refill }}:{{ .Values.DB_PORT__Refill }}/Refill"
                jdbc_user => {{ .Values.DB_HOST__password }}
                jdbc_password => {{ .Values.DB_HOST__password }}
                statement => "SELECT JSON_EXTRACT(rd.value, '$.partnerProperties') as partner_properties FROM reseller_dynamic_data rd INNER JOIN commission_receivers cr ON rd.receiver_key = cr.receiver_key WHERE cr.tag = ?"
                prepared_statement_bind_values => "%{[oms.buyer.id]}"
                target => "buyer_partner_data"
                prepared_statement_name => "buyer_partner_properties_lookup"
                use_prepared_statements => true
            }

            ruby {
                code => '
                    begin
                        require "json"
                        buyer_partner_data = event.get("buyer_partner_data")

                        if buyer_partner_data && buyer_partner_data.is_a?(Array) && !buyer_partner_data.empty?
                            partner_data = buyer_partner_data.first
                            partner_properties_json = partner_data["partner_properties"]

                            if partner_properties_json && !partner_properties_json.empty?
                                partner_properties = JSON.parse(partner_properties_json)

                                if partner_properties && partner_properties.is_a?(Array)
                                    partner_types = partner_properties.map { |p| p["partnerType"] }.compact.join("|")
                                    event.set("oms.buyer.partnerTypes", partner_types)

                                    partner_categories = partner_properties.map { |p| p["partnerCategory"] }.compact.join("|")
                                    event.set("oms.buyer.partnerCategories", partner_categories)

                                    partner_value_classes = partner_properties.map { |p| p["partnerValueClass"] }.compact.join("|")
                                    event.set("oms.buyer.partnerValueClasses", partner_value_classes)
                                end
                            end
                        end

                        # Remove the temporary field
                        event.remove("buyer_partner_data")
                    rescue => e
                        logger.error("Error processing buyer partner properties: #{e.message}")
                    end
                '
            }
        }

        ruby
        {
               code => "
                 require 'date'
                 week_n = event.get('timestamp').time.strftime '%V'
                 month_n = event.get('timestamp').time.strftime '%m'
                 year_n = event.get('timestamp').time.strftime '%Y'
                 if(week_n == '01' && month_n == '12')
                     year_n = (year_n.to_i + 1)
                     week_num = year_n.to_s + 'w' + week_n.to_s
                 elsif (month_n == '01' && week_n.to_i > 50)
                     year_n = (year_n.to_i - 1)
                     week_num = year_n.to_s + 'w' + week_n.to_s
                 else
                     week_num = year_n + 'w' + week_n
                 end
                 event.set('[@metadata][week_num]', week_num)
                 "
        }
    }
    else if [oms.orderType] == "N/A" and [eventName] == "UPDATE_INVOICE_DATAFEED" and [user.userId] == "cockpit" and [resultCode] == "0"
    {
        # Add prune filter to whitelist only required fields
        prune {
            whitelist_names => ["^oms.invoices$", "^oms.orderId$", "^timestamp$"]
        }

        ruby {
            code => '
                begin
                    require "net/http"
                    require "json"
                    require "uri"
                    require "openssl"

                    # Retry configuration
                    max_retries = 5
                    base_sleep = 0.2  # 200ms
                    order_id = event.get("[oms.orderId]")

                    existing_invoices = nil
                    retry_count = 0

                    # Retry loop with exponential backoff
                    while retry_count <= max_retries
                        begin
                            # Prepare Elasticsearch query using _search API across all order_data_lake indices
                            uri = URI("https://{{ .Values.HOST__elasticsearch }}:{{ .Values.PORT__elasticsearch }}/order_data_lake_*/_search")
                            http = Net::HTTP.new(uri.host, uri.port)
                            http.use_ssl = true
                            http.ca_file = "/opt/seamless/conf/logstash/cert/http_ca.crt"
                            http.verify_mode = OpenSSL::SSL::VERIFY_PEER

                            http.read_timeout = 5
                            http.open_timeout = 5

                            # Search query to find document by ID
                            search_body = {
                                "query" => {
                                    "term" => {
                                        "_id" => order_id
                                    }
                                },
                                "_source" => ["oms.invoices"],
                                "size" => 1
                            }

                            request = Net::HTTP::Post.new(uri)
                            request["Content-Type"] = "application/json"
                            request.basic_auth("{{ .Values.HOST__elasticsearch_user }}", "{{ .Values.HOST__elasticsearch_pass }}")
                            request.body = search_body.to_json

                            response = http.request(request)

                            if response.code == "200"
                                # Parse search response
                                search_result = JSON.parse(response.body)
                                hits = search_result["hits"]["hits"]

                                if hits && hits.length > 0
                                    # Document found, extract invoices
                                    existing_invoices = hits[0]["_source"]["oms.invoices"] if hits[0]["_source"]
                                    break
                                else
                                    # Document not found in search results, could be timing issue
                                    if retry_count < max_retries
                                        sleep_time = base_sleep * (2 ** retry_count)
                                        logger.warn("Document #{order_id} not found in search results, retrying in #{sleep_time}s (attempt #{retry_count + 1}/#{max_retries + 1})")
                                        sleep(sleep_time)
                                        retry_count += 1
                                    else
                                        logger.warn("Document #{order_id} not found after #{max_retries} retries, proceeding without existing data")
                                        break
                                    end
                                end
                            else
                                # HTTP error
                                if retry_count < max_retries
                                    sleep_time = base_sleep * (2 ** retry_count)
                                    logger.warn("Elasticsearch search failed with status #{response.code}, retrying in #{sleep_time}s (attempt #{retry_count + 1}/#{max_retries + 1})")
                                    sleep(sleep_time)
                                    retry_count += 1
                                else
                                    logger.error("Elasticsearch search failed after #{max_retries} retries with status #{response.code}")
                                    break
                                end
                            end
                        rescue => e
                            if retry_count < max_retries
                                sleep_time = base_sleep * (2 ** retry_count)
                                logger.warn("Elasticsearch connection error: #{e.message}, retrying in #{sleep_time}s (attempt #{retry_count + 1}/#{max_retries + 1})")
                                sleep(sleep_time)
                                retry_count += 1
                            else
                                logger.error("Elasticsearch connection failed after #{max_retries} retries: #{e.message}")
                                break
                            end
                        end
                    end

                    # Merge invoice logic
                    incoming_invoices = event.get("[oms.invoices]")

                    if incoming_invoices && incoming_invoices.is_a?(Array) && existing_invoices && existing_invoices.is_a?(Array)
                        # Flatten all existing invoice entries and create a map by productCode
                        existing_entries_map = {}
                        existing_invoices.each do |existing_invoice|
                            existing_entries = existing_invoice["invoice.invoiceEntries"] || []
                            existing_entries.each do |entry|
                                product_code = entry["productCode"]
                                if product_code
                                    existing_entries_map[product_code] = {
                                        "entry" => entry,
                                        "invoice" => existing_invoice
                                    }
                                end
                            end
                        end

                        # Process incoming invoices and merge entries by productCode
                        merged_invoices = []
                        incoming_invoices.each do |incoming_invoice|
                            merged_invoice = incoming_invoice.dup
                            incoming_entries = incoming_invoice["invoice.invoiceEntries"] || []
                            merged_entries = []

                            incoming_entries.each do |incoming_entry|
                                product_code = incoming_entry["productCode"]
                                existing_data = existing_entries_map[product_code]

                                if existing_data
                                    existing_entry = existing_data["entry"]
                                    # Merge the entries
                                    merged_entry = {}

                                    # Get all unique keys from both entries
                                    all_keys = (incoming_entry.keys + existing_entry.keys).uniq

                                    all_keys.each do |key|
                                        incoming_value = incoming_entry[key]
                                        existing_value = existing_entry[key]

                                        if incoming_value.nil?
                                            # Incoming doesnt have this key, use existing
                                            merged_entry[key] = existing_value
                                        elsif incoming_value == "" || incoming_value == "N/A"
                                            # Incoming has empty/N/A, prefer existing if it exists
                                            merged_entry[key] = existing_value || incoming_value
                                        else
                                            # Incoming has actual value, use it
                                            merged_entry[key] = incoming_value
                                        end
                                    end

                                    merged_entries << merged_entry
                                    # Mark this existing entry as processed
                                    existing_entries_map.delete(product_code)
                                else
                                    # Entry only exists in incoming, add it as is
                                    merged_entries << incoming_entry
                                end
                            end

                            # Update the invoice with merged entries
                            merged_invoice["invoice.invoiceEntries"] = merged_entries
                            merged_invoices << merged_invoice
                        end

                        # Add any remaining existing entries that were not matched to any incoming entry
                        remaining_entries_by_invoice = {}
                        existing_entries_map.each_value do |data|
                            existing_invoice = data["invoice"]
                            invoice_id = existing_invoice["invoice.id"]

                            remaining_entries_by_invoice[invoice_id] ||= {
                                "invoice" => existing_invoice,
                                "entries" => []
                            }
                            remaining_entries_by_invoice[invoice_id]["entries"] << data["entry"]
                        end

                        # Create invoices for remaining entries
                        remaining_entries_by_invoice.each_value do |data|
                            remaining_invoice = data["invoice"].dup
                            remaining_invoice["invoice.invoiceEntries"] = data["entries"]
                            merged_invoices << remaining_invoice
                        end

                        # Ensure each invoice entry has serials field in invoiceEntryProperties
                        merged_invoices.each do |invoice|
                            if invoice["invoice.invoiceEntries"]
                                invoice["invoice.invoiceEntries"].each do |entry|
                                    if entry["invoiceEntryProperties"]
                                        entry["invoiceEntryProperties"]["serials"] ||= ""
                                    else
                                        entry["invoiceEntryProperties"] = {"serials" => ""}
                                    end
                                end
                            end
                        end

                        # Update the event with merged invoices
                        event.set("[oms.invoices]", merged_invoices)

                        logger.info("Successfully merged invoice entries by productCode for order #{order_id}")
                    elsif existing_invoices.nil?
                        logger.info("No existing document found for order #{order_id}, using incoming invoices only")
                    else
                        logger.info("Using incoming invoices for order #{order_id}")
                    end

                rescue => e
                    logger.error("Error in invoice merging process for order #{order_id}: #{e.message}")
                    logger.error("Backtrace: #{e.backtrace.join("\n")}")
                end
            '
        }

        ruby
        {
               code => "
                 require 'date'
                 week_n = event.get('timestamp').time.strftime '%V'
                 month_n = event.get('timestamp').time.strftime '%m'
                 year_n = event.get('timestamp').time.strftime '%Y'
                 if(week_n == '01' && month_n == '12')
                     year_n = (year_n.to_i + 1)
                     week_num = year_n.to_s + 'w' + week_n.to_s
                 elsif (month_n == '01' && week_n.to_i > 50)
                     year_n = (year_n.to_i - 1)
                     week_num = year_n.to_s + 'w' + week_n.to_s
                 else
                     week_num = year_n + 'w' + week_n
                 end
                 event.set('[@metadata][week_num]', week_num)
                 "
        }


    }
    else
    {
        ruby
        {
            code => 'puts "Dropping record"'
        }
        drop {}
    }
  }
  else
  {
       #data-feed json is invalid, so prepare index name with @timestamp
       #Doc Id of skipped txn would be random number generated by ES
       prune
       {
             blacklist_names => ["^log$","^tags$","^agent$","^message$","^path$","^@version$","^host$","^ecs$","^input$","^cloud$","^event$"]
       }
       ruby
       {
             code => "
             puts 'Transaction skipped due to invalid JSON format with @timestamp:'
             puts event.get('@timestamp')
             require 'date'
             week_n = event.get('@timestamp').time.strftime '%V'
             month_n = event.get('@timestamp').time.strftime '%m'
             year_n = event.get('@timestamp').time.strftime '%Y'
             if(week_n == '01' && month_n == '12')
                 year_n = (year_n.to_i + 1)
                 week_num = year_n.to_s + 'w' + week_n.to_s
             else if (month_n == '01' && week_n.to_i > 50)
                 year_n = (year_n.to_i - 1)
                 week_num = year_n.to_s + 'w' + week_n.to_s
             else
                 week_num = year_n + 'w' + week_n
             end
             end
             event.set('[@metadata][week_num]', week_num)
             "
       }
   }
}

output {
    if "_jsonparsefailure" in [tags]
    {
        #if data-feed json is not in correct format, insert it to skipped_txn index
        elasticsearch {
            action => "index"
            hosts => [ "{{ .Values.HOST__elasticsearch }}:{{ .Values.PORT__elasticsearch }}" ]
            user => {{ .Values.HOST__elasticsearch_user }}
            password => {{ .Values.HOST__elasticsearch_pass }}
            ssl => true
            cacert => "/opt/seamless/conf/logstash/cert/http_ca.crt"
            index => "skipped_order_%{[@metadata][week_num]}"

        }
    }
    else
    {
        elasticsearch {
            action => "update"
            hosts => ["{{ .Values.HOST__elasticsearch }}:{{ .Values.PORT__elasticsearch }}"]
            user => {{ .Values.HOST__elasticsearch_user }}
            password => {{ .Values.HOST__elasticsearch_pass }}
            ssl => true
            cacert => "/opt/seamless/conf/logstash/cert/http_ca.crt"
            index => "order_data_lake_%{[@metadata][week_num]}"
            document_id => "%{oms.orderId}"
            doc_as_upsert => true
        }
    }
    stdout { codec => rubydebug }
}
