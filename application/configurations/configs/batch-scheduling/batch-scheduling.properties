#--------------------------------------------------------------------------------------
# Batch Scheduling Application
#-------------------------------------------------------------------------------------
spring.application.name=batch-scheduling
server.port=8085
server.servlet.context-path=/bss
#This parameter specifies the maximum size permitted for uploaded files. The default is 1MB.
spring.servlet.multipart.max-file-size=1024KB
#This parameter specifies the maximum size allowed for multipart/form-data requests. The default is 10MB.
spring.servlet.multipart.max-request-size=1228KB

# Swagger UI URL http://localhost:8085/bss/swagger-ui/index.html
# http://localhost:8085/bss/v2/api-docs
 # http://localhost:8085/bss/v3/api-docs

springdoc.swagger-ui.disable-swagger-default-url=true
messages.source.files.path=/opt/seamless/conf/batch-scheduling
logging.config=/opt/seamless/conf/batch-scheduling/log4j2.xml
## Workaround for SB-2.6.x and SpringFox which assumes that the path matching strategy of Spring MVCant-path-matcher. However the default matching strategy of Spring Boot 2.6.x is path-pattern-matcher
spring.mvc.pathmatch.matching-strategy=ant-path-matcher

#-------------------------------------------------------------------------------------
# ElastiSearch  properties
#-------------------------------------------------------------------------------------
bss.elasticsearch.userName={{ .Values.HOST__elasticsearch_user }}
bss.elasticsearch.password={{ .Values.HOST__elasticsearch_pass }}
bss.elasticsearch.1.url={{ .Values.HOST__elasticsearch }}
bss.elasticsearch.1.port={{ .Values.PORT__elasticsearch }}
#bss.elasticsearch.2.url={{ .Values.HOST__elasticsearch }}
#bss.elasticsearch.2.port={{ .Values.PORT__elasticsearch }}

#when java api is enabled, the hlrc will be disabled
#bss.elasticsearch.java-api.enabled=true

#api compatibility apply only to hlrc
#can be set true only when elastic server is at least version 7.11 and shall be true when version is 8.x
#bss.elasticsearch.apiCompatibilityMode=true
#-------------------------------------------------------------------------------------
# Database connection properties
#-------------------------------------------------------------------------------------
spring.datasource.url=jdbc:mariadb://{{ .Values.DB_HOST__batchschedulingsystem }}:{{ .Values.DB_PORT__batchschedulingsystem }}/batchschedulingsystem
spring.datasource.username=refill
spring.datasource.password={{ .Values.DB_HOST__password }}
#-------------------------------------------------------------------------------------
# JPA properties
#-------------------------------------------------------------------------------------
spring.jpa.database-platform=org.hibernate.dialect.MariaDBDialect
spring.jpa.properties.hibernate.format_sql=true
spring.jpa.properties.hibernate.jdbc.time_zone=UTC

#-------------------------------------------------------------------------------------
# Thymeleaf configuration
#-------------------------------------------------------------------------------------
spring.thymeleaf.check-template-location=true
spring.thymeleaf.prefix=file:/opt/seamless/conf/batch-scheduling/notifications/
spring.thymeleaf.suffix=.txt
spring.thymeleaf.mode=TEXT
spring.thymeleaf.encoding=UTF-8
spring.thymeleaf.content-type=text/plain
spring.thymeleaf.cache=false

#-------------------------------------------------------------------------------------
# CORS config
#-------------------------------------------------------------------------------------
cors.enable=false
#comma separated origin list
cors.allowedorigins=http://localhost:9090,http://localhost:9091
#-------------------------------------------------------------------------------------
# Localization config
#-------------------------------------------------------------------------------------
bss.supported.languages=en,ar,fr
locale.language=en
locale.userLangPreferenceEnabled=false
locale.languageHeaderName=language


#-------------------------------------------------------------------------------------
# Batch properties
#-------------------------------------------------------------------------------------
### clientId will be helpfull to distinguish the client
### for which ftl should be used and below config will
### be used in bss.freemarker.file.path
#bss.freemarker.clientId=tt
bss.freemarker.file.path=/opt/seamless/conf/batch-scheduling/templates
###/${bss.freemarker.clientId}

bss.tmp.file.path=/var/tmp

### turn this property to true to merge error and retry file
bss.retry.file.merge=false

#-------------------------------------------------------------------------------------
# Pending Jobs DB Scanner properties
#-------------------------------------------------------------------------------------
# Frequency to scan database for jobs that are pending to be scheduled
bss.pendingJobScanner.frequency.milliseconds=120000
# Execute jobs having scheduled date older than <olderThan> seconds
bss.pendingJobScanner.olderThan.milliseconds=60000
# Limit the number of jobs to run each time the scanner runs
bss.pendingJobScanner.nbjobs.limit=10
# Limit the number of jobs to run in parallel
bss.pendingJobScanner.concurrentJobs.limit=5
# Duration (in minutes) before considering a running batch as stuck.
# Some components do not support two simultaneous executions of batches (e.g. contract).
# To not have some batches locked and waiting forever the end of the execution of a previous batch
# then a batch that has the 'processing' status and that don't update the database for some time
# will be considered as dead
bss.pendingJobScanner.processing.inactivity.timeout=30

#-------------------------------------------------------------------------------------
# OSM service connection (Object Store Manager)
#-------------------------------------------------------------------------------------
bss.osmApi.url=http://svc-object-store:3000/osm
bss.osmApi.uri=/v1/resource/
bss.osmApi.connectionTimeout=5000
bss.osmApi.requestTimeout=60000
#-------------------------------------------------------------------------------------
# Inventory Management System (through nginx)
#-------------------------------------------------------------------------------------
bss.imsApi.connectionTimeout=5000
bss.imsApi.requestTimeout=60000
bss.imsApi.url=http://svc-nginx:18080/api/ims
bss.imsApi.importInventoryUri=/v1/bulk-import

bss.imsApi.importInventoryUri.useFullPath=true
bss.imsApi.importInventoryUri.useFullPath.url=http://svc-order-management:9595/oms/v2/bulk-inventory-import

bss.imsApi.updateInventoryUri=/v1/inventory/update/bulk-import
bss.imsApi.deleteInventoryUri=/v1/batches
bss.imsApi.updateExternalInventoryUri=/v1/external/bulk-update
#-------------------------------------------------------------------------------------
# Dealer Management System (through nginx)
#-------------------------------------------------------------------------------------
bss.dmsApi.url=http://svc-nginx:18080/api/dms
bss.dmsApiV2.url=http://svc-nginx:18080/api/dms
bss.dmsApi.connectionTimeout=5000
bss.dmsApi.requestTimeout=60000
bss.dmsApi.socketTimeout=60000
bss.dmsApi.importResellerUri=/v1/resellers/create
bss.dmsApi.updateResellerUri=/v2/auth/bulkUpdate
bss.dmsApi.bulkUpdateResellerExtraParams=/v2/auth/bulkUpdateResellerExtraParams
bss.dmsApi.bulkAddResellerUsersUri=/v1/resellers/bulkAddResellerUsers
bss.dmsApi.bulkUpdateResellerUsersUri=/v2/auth/bulkUpdate
bss.dmsApi.getResellerInfoUri=/auth/getResellerInfo
bss.dmsApi.changeResellerParentUri=/v2/auth/bulkChangeParent
bss.dmsApi.changeResellerStateUri=/auth/v1/resellerChangeState
bss.dmsApi.searchResellersByAttributeUri=/auth/bulkSearchResellersByAttribute
bss.dmsApi.areaDemarcationUri=/auth/areaDemarcation
bss.dmsApi.IDMAreaDemarcationUri=/auth/IDMareaDemarcation
#-------------------------------------------------------------------------------------
# Voucher Management System (through nginx)
#-------------------------------------------------------------------------------------
bss.vmsApi.url=http://svc-nginx:18080/api/job
bss.vmsApi.connectionTimeout=5000
bss.vmsApi.requestTimeout=60000
bss.vmsApi.blockVoucherUri=/v1/batch/BLOCK
bss.vmsApi.unblockVoucherUri=/v1/batch/UNBLOCK
bss.vmsApi.extendExpiryVoucherUri=/v1/batch/EXTEND_EXPIRY
bss.vmsApi.reconcileVoucherUri=/v1/batch/RECONCILE
bss.vmsApi.distributeVoucherUri=/v1/batch/DISTRIBUTE

#-------------------------------------------------------------------------------------
# Order Management System (through nginx)
#-------------------------------------------------------------------------------------

bss.omsApi.url=http://svc-nginx:18080/api/oms
bss.omsApi.connectionTimeout=5000
bss.omsApi.requestTimeout=60000

bss.omsApi.formDataEnabled=false
### if bss.omsApi.omsFormDataEnabled=true then below url should be /v1/orders
### incase of bss.omsApi.formDataEnabled=false below url should be /v2/orders
#bss.omsApi.importOrderUri=/v1/orders
bss.omsApi.importOrderUri=/v2/orders

#-------------------------------------------------------------------------------------
# Quota Management System (through nginx)
#-------------------------------------------------------------------------------------
bss.samsApi.url=http://svc-nginx:18080/api/quota-management-system
bss.samsApi.connectionTimeout=5000
bss.samsApi.requestTimeout=60000
bss.samsApi.importStockAllocationUri=/v1/quota/bulk
bss.samsApi.deleteStockAllocationUri=/v1/quota/revert
bss.samsApi.confirmStockAllocationUri=/v1/quota/keep

#-------------------------------------------------------------------------------------
# Asset Management System (through nginx)
#-------------------------------------------------------------------------------------
bss.assetApi.url=http://svc-nginx:18080/api/assetmanagement
bss.assetApi.connectionTimeout=5000
bss.assetApi.requestTimeout=60000
bss.assetApi.socketTimeout=60000
bss.assetApi.importAssetMetaDataUri=/v1/asset/bulkAddAssetMetaData
bss.assetApi.addBulkAssetMetaDataUri=/v1/asset/importBulkCreateAsset

#-------------------------------------------------------------------------------------
# Product (through nginx)
#-------------------------------------------------------------------------------------

bss.product.url=http://svc-nginx:18080/api/pms
bss.product.importProductUri=/v1/product-variant-bulk/create
bss.product.importProductsWithVariantUri=/v1/products
bss.product.connectionTimeout=5000
bss.product.requestTimeout=60000

#-------------------------------------------------------------------------------------
# HTTPStatus Codes List to be used for event success or failed accordingly
#-------------------------------------------------------------------------------------
bss.list.httpSuccessCodes=200,202

#-------------------------------------------------------------------------------------
# HTTP Gateway Error Codes List for which automatic retry mechanism will be enabled based on gatewayErrorsAutomaticRetry config parameter
#-------------------------------------------------------------------------------------
bss.list.httpGatewayErrorCodes=502,504


#-------------------------------------------------------------------------------------
# RateCard Configuration (through nginx)
#-------------------------------------------------------------------------------------
bss.rateCardApi.url=http://svc-nginx:18080/api/els
bss.rateCardApi.uri=/v1/ratecard
bss.rateCardApi.connectionTimeout=5000
bss.rateCardApi.resquestTimeout=60000

#-------------------------------------------------------------------------------------
# Authentication Configuration (through nginx)
#-------------------------------------------------------------------------------------
bss.idmsApi.baseUrl=http://svc-nginx:18080
bss.idmsApi.loginUri=/login-backend
bss.idmsApi.loginChannel=SEAMLESS-UNIFIED
# TODO MKS: Need enhancements
bss.idmsApi.loginUserId=OPERATOR
bss.idmsApi.loginPassword=2023
#-------------------------------------------------------------------------------------
# TXE (through nginx)
#-------------------------------------------------------------------------------------

bss.txeApi.url=http://svc-nginx:18080/api/txe
bss.txeApi.importTransferUri=/v1/bulkRequestTransfer
bss.txeApi.importTransferReversalUri=/v1/bulkReversalRequest
bss.txeApi.connectionTimeout=5000
bss.txeApi.requestTimeout=60000

#-------------------------------------------------------------------------------------
# Region Management (through nginx)
#-------------------------------------------------------------------------------------

bss.rgmsApi.url=http://svc-nginx:18080/api/rgms
bss.rgmsApi.createRegionHierarchy=/v1/region/?allowUpdate=true
bss.rgmsApi.createRegionHierarchyForIDM=/v1/region/?allowUpdate=true&demarcation=true
bss.rgmsApi.connectionTimeout=5000
bss.rgmsApi.requestTimeout=60000


#-------------------------------------------------------------------------------------
# SCC-Engine (through nginx)
#-------------------------------------------------------------------------------------

bss.sccApi.bulkimportParticipateTargetAudience=http://svc-nginx:18080/api/scc/v1/campaign/participate-target-audience
bss.sccApi.connectionTimeout=5000
bss.sccApi.requestTimeout=60000

#-------------------------------------------------------------------------------------
# Notification Manager (through nginx)
#-------------------------------------------------------------------------------------
bss.notification.management.proxy.uri=http://svc-nginx:18080/api/notificationmanager
rest.template.http.max.idle=50000
rest.template.http.keep.alive=30000
rest.template.http.connection.timeout=20000
rest.template.http.read.timeout=60000

bss.notification.language.default=en_US
bss.notification.sender.email=noreply@seamless.se
bss.notification.sender.sms=Seamless
# List of recipients to notify. Empty or list amongst ADMIN and SUBMITTER
bss.notification.recipients=ADMIN,SUBMITTER
# Possible values:
# BOTH: send notification by SMS and eMail
# SMS: when the recipient has an MSISDN sends the notification by SMS otherwise by eMail
# EMAIL: when the recipient has an e-mail sends the notification by eMail otherwise by SMS
bss.notification.submitter.preferred.channel=BOTH
bss.notification.admin.preferred.channel=BOTH
bss.notification.admin.msisdn=21690xxxxxx
bss.notification.admin.email=test@seamless.se


#-------------------------------------------------------------------------------------
# Unified Client - Reference Generator
#-------------------------------------------------------------------------------------
bss.ersReferenceGenerator.class_name=com.seamless.common.referencegeneration.TimestampReferenceGenerator
bss.ersReferenceGenerator.timestamp_repeat_warning_count=10
bss.ersReferenceGenerator.reference_counter_length=10
bss.ersReferenceGenerator.node_id=01


#-------------------------------------------------------------------------------------
# contract (through nginx) This is only GP specific
#-------------------------------------------------------------------------------------

bss.contract.url=http://svc-nginx:18080/api/acms
bss.contract.importContractsPricingList=/v2/contracts/pricing-list/import
bss.contract.connectionTimeout=5000
bss.contract.requestTimeout=60000

#-------------------------------------------------------------------------------------
# Batch Reseller specific properties
#-------------------------------------------------------------------------------------

# Map enabled field to status
bss.reseller.mapping.enabledToStatus={'1':'Active', '0':'Deactivated', 'default':'Deactivated'}
bss.reseller.mapping.flagToBoolean={'0':'false', '1':'true', 'default':'false'}
bss.reseller.updateSubType=Users_Unitel_Update

bss.reseller.fieldValidationRegExp={\
    'phone':'(216)?[0-9]{8}' ,\
    'username':'[A-Z0-9-_]+' \
    }
bss.reseller.defaultAllowedFor=NONE

bss.reseller.id=Generic
bss.reseller.allowedFor=${bss.reseller.defaultAllowedFor}
# Default scheduling type (when not provided in the RESP request)
bss.reseller.processor.schedType=immediate
# Scheduling time in spring cron format (when scheduling type is 'scheduled')
bss.reseller.processor.schedTime=0 0 1 * * ?
bss.reseller.processor.schedTypeDelay-sec=60
bss.reseller.processor.failOnError=false
bss.reseller.processor.chunkSize=10
# Number of chunks executed in parallel
# bss.reseller.processor.parallelChunkNb=10
bss.reseller.processor.maxRetryCount=3
#after what number of minutes (from the first retry) another retry should be considered
bss.reseller.processor.retryDelay=10
bss.reseller.file.uploadDescription=Reseller ${bss.reseller.id} import file
bss.reseller.file.supportedFormats=CSV,JSON
bss.reseller.file.format=CSV
bss.reseller.file.csv.freemarkerTemplate=reseller_import.ftl
bss.reseller.file.csv.header=fullname,cin,phone,gouvernorat_id,delegation_id,code_postal_id,address,fax,matricule_fiscal,username,otp,password,enabled,motif_desactivation,email,groupe,parent_user,code_conventionnel,digitalised,allowreport,allow_webservice_sell,email_responsable,Localisation
bss.reseller.file.csv.hasHeader=true
bss.reseller.file.csv.defaultSeparator=;
bss.reseller.file.csv.fieldMapping.resellerId=COLUMN:username
bss.reseller.file.csv.fieldMapping.resellerName=COLUMN:fullname
bss.reseller.file.csv.fieldMapping.resellerMSISDN=COLUMN:phone
bss.reseller.file.csv.fieldMapping.resellerTypeId=COLUMN:groupe
bss.reseller.file.csv.fieldMapping.parentResellerId=COLUMN:parent_user
bss.reseller.file.csv.fieldMapping.status=MAP_COLUMN:enabledToStatus:enabled
bss.reseller.file.csv.fieldMapping.address_email=COLUMN:email
#bss.reseller.file.csv.fieldMapping.address_fax=COLUMN:fax
bss.reseller.file.csv.fieldMapping.address_street=COLUMN:address
#bss.reseller.file.csv.fieldMapping.address_zip=COLUMN:code_postal_id
bss.reseller.file.csv.fieldMapping.extraParam_region=COLUMN:gouvernorat_id
bss.reseller.file.csv.fieldMapping.extraParam_delegation=COLUMN:delegation_id
bss.reseller.file.csv.fieldMapping.extraParam_matricule_fiscal=COLUMN:matricule_fiscal
bss.reseller.file.csv.fieldMapping.extraParam_customer_national_identification_id=COLUMN:cin
bss.reseller.file.csv.fieldMapping.extraParam_one_time_password=COLUMN:otp
bss.reseller.file.csv.fieldMapping.extraParam_motte_de_passe=COLUMN:password
bss.reseller.file.csv.fieldMapping.extraParam_reason_for_activation=COLUMN:motif_desactivation
bss.reseller.file.csv.fieldMapping.extraParam_code_external_system=COLUMN:code_conventionnel
bss.reseller.file.csv.fieldMapping.extraParam_allow_mobile_app=COLUMN:digitalised
bss.reseller.file.csv.fieldMapping.extraParam_allow_report=COLUMN:allowreport
bss.reseller.file.csv.fieldMapping.extraParam_allow_mobile_sell=COLUMN:allow_webservice_sell
bss.reseller.file.csv.fieldMapping.extraParam_email_responsible=COLUMN:email_responsable
bss.reseller.file.csv.fieldMapping.extraParam_postal_code=COLUMN:code_postal_id
bss.reseller.file.csv.fieldMapping.extraParam_fax=COLUMN:fax
bss.reseller.file.csv.fieldMapping.extraParam_zone_localisation=COLUMN:Localisation
bss.reseller.file.csv.fieldValidationRegExp=${bss.reseller.fieldValidationRegExp}

#bss.reseller.file.csv.fieldMapping.user_userId=LIST_COLUMN:user0:USERID0

#-------------------------------------------------------------------------------------
# Batch Reseller Users
#-------------------------------------------------------------------------------------
# Map enabled field to status
bss.reselleruser.mapping.enabledToStatus={'1':'Active', '0':'Deactivated', 'default':'Deactivated'}
bss.reselleruser.mapping.flagToBoolean={'0':'false', '1':'true', 'default':'false'}
bss.reselleruser.updateSubType=resellerUser_import

bss.reselleruser.fieldValidationRegExp={\
    'phone':'(216)?[0-9]{13}' ,\
    'name':'[A-Za-z0-9-_]+' \
    }
bss.reselleruser.defaultAllowedFor=NONE

bss.reselleruser.id=Generic
bss.reselleruser.allowedFor=${bss.reselleruser.defaultAllowedFor}
# Default scheduling type (when not provided in the RESP request)
bss.reselleruser.processor.schedType=immediate
# Scheduling time in spring cron format (when scheduling type is 'scheduled')
bss.reselleruser.processor.schedTime=0 0 1 * * ?
bss.reselleruser.processor.schedTypeDelay-sec=60
bss.reselleruser.processor.failOnError=false
bss.reselleruser.processor.chunkSize=10
# Number of chunks executed in parallel
# bss.reselleruser.processor.parallelChunkNb=10
bss.reselleruser.processor.maxRetryCount=3
#after what number of minutes (from the first retry) another retry should be considered
bss.reselleruser.processor.retryDelay=10
bss.reselleruser.file.uploadDescription=Reseller ${bss.reselleruser.id} import file
bss.reselleruser.file.supportedFormats=CSV
bss.reselleruser.file.format=CSV
bss.reselleruser.file.csv.freemarkerTemplate=resellerUser_import.ftl
bss.reselleruser.file.csv.header=email,name,password,phone,record_id,reseller_id,role_id,user_id
bss.reselleruser.file.csv.hasHeader=true
bss.reselleruser.file.csv.defaultSeparator=;
bss.reselleruser.file.csv.fieldMapping.email=COLUMN:email
bss.reselleruser.file.csv.fieldMapping.name=COLUMN:name
bss.reselleruser.file.csv.fieldMapping.password=COLUMN:password
bss.reselleruser.file.csv.fieldMapping.phone=COLUMN:phone
bss.reselleruser.file.csv.fieldMapping.recordId=COLUMN:record_id
bss.reselleruser.file.csv.fieldMapping.resellerId=COLUMN:reseller_id
bss.reselleruser.file.csv.fieldMapping.roleId=COLUMN:role_id
bss.reselleruser.file.csv.fieldMapping.userId=COLUMN:user_id

bss.reselleruser.file.csv.fieldValidationRegExp=${bss.reselleruser.fieldValidationRegExp}


#-------------------------------------------------------------------------------------
# Batch Inventory specific properties
#-------------------------------------------------------------------------------------

# Map brand to productSKU
bss.inventory.mapping.dsaBrandToSKU={\
    'TT':'TT_SIM_DSA',\
    'CSS':'CSS_SIM_DSA',\
    'Elissa':'ESS_SIM_DSA',\
    'Tarajji':'TARAJI_SIM_DSA',\
    'default':'TT_SIM_DSA'\
    }
bss.inventory.mapping.nonDsaBrandToSKU={\
    '0001':'TT_SIM_NON_DSA',\
    '0004':'CSS_SIM_NON_DSA',\
    '0003':'ESS_SIM_NON_DSA',\
    '0002':'TARAJI_SIM_NON_DSA',\
    'default':'TT_SIM_NON_DSA'\
    }

bss.inventory.fieldValidationRegExp={\
    'MSISDN':'(216)?[0-9]{8}' \
    }

bss.inventory.defaultAllowedFor=ALL

bss.inventory.updateSubType=

bss.inventory.id=Generic
bss.inventory.allowedFor=${bss.inventory.defaultAllowedFor}
bss.inventory.processor.schedType=immediate
# Scheduling time in spring cron format (when scheduling type is 'scheduled')
bss.inventory.processor.schedTime=0 0 1 * * ?
bss.inventory.processor.schedTypeDelay-sec=30
bss.inventory.processor.failOnError=true
bss.inventory.processor.chunkSize=15
# Number of chunks executed in parallel
# bss.inventory.processor.parallelChunkNb=10
bss.inventory.processor.maxRetryCount=3
#after what number of minutes (from the first retry) another retry should be considered
bss.inventory.processor.retryDelay=10
bss.inventory.file.uploadDescription=Inventory ${bss.inventory.id} import file
bss.inventory.file.supportedFormats=CSV,JSON
bss.inventory.file.format=CSV
bss.inventory.file.csv.freemarkerTemplate=inventory_import.ftl
bss.inventory.file.csv.header=SIM,BRAND,CODE_BRAND
bss.inventory.file.csv.hasHeader=true
bss.inventory.file.csv.defaultSeparator=;
bss.inventory.file.csv.fieldMapping.batchId=CONSTANT:
bss.inventory.file.csv.fieldMapping.owner=SYSTEM:uploadedBy
bss.inventory.file.csv.fieldMapping.startNo=CONSTANT:
bss.inventory.file.csv.fieldMapping.endNo=CONSTANT:
bss.inventory.file.csv.fieldMapping.state=CONSTANT:Available
bss.inventory.file.csv.fieldMapping.idType=CONSTANT:SERIAL
bss.inventory.file.csv.fieldMapping.serialNo=COLUMN:SIM
bss.inventory.file.csv.fieldMapping.locationId=SYSTEM:uploadedBy
bss.inventory.file.csv.fieldMapping.productSKU=MAP_COLUMN:dsaBrandToSKU:BRAND
bss.inventory.file.csv.fieldMapping.data_brandCode=COLUMN:CODE_BRAND

bss.inventory.mapping.ownerTocanonicalId={\
    'PROVANTAGE (Pty) Ltd -GP Randburg Office(PMG Warehouse)':'RWM1',\
    'default':'%|FILE_VALUE|%'\
    }

bss.inventory.mapping.subInventoryToResellerType={\
    'READY-DELV':'DIST',\
    'RFD-OTHER':'GPC',\
    'default':'%|FILE_VALUE|%'\
    }


#-------------------------------------------------------------------------------------
# Batch External Inventory Update
#-------------------------------------------------------------------------------------
bss.inventory.type[0].id=Stock_Allocation
bss.inventory.type[0].operation=EXTERNAL
bss.inventory.type[0].allowedFor=${bss.inventory.defaultAllowedFor}
bss.inventory.type[0].processor.schedType=immediate
# Scheduling time in spring cron format (when scheduling type is 'scheduled')
bss.inventory.type[0].processor.schedTime=0 0 1 * * ?
bss.inventory.type[0].processor.schedTypeDelay-sec=30
bss.inventory.type[0].processor.failOnError=true
bss.inventory.type[0].processor.chunkSize=100
# Number of chunks executed in parallel
# bss.inventory.type[0].processor.parallelChunkNb=10
bss.inventory.type[0].file.uploadDescription=Inventory ${bss.inventory.type[0].id} import file
bss.inventory.type[0].file.supportedFormats=CSV
bss.inventory.type[0].file.format=CSV
bss.inventory.type[0].file.csv.freemarkerTemplate=external_inventory_update.ftl
bss.inventory.type[0].file.csv.header=TRANSACTION_ID,TRANSACTION_TIME,ITEM_CODE,QUANTITY,TRANSACTION_TYPE,SUBINVENTORY
bss.inventory.type[0].file.csv.hasHeader=true
bss.inventory.type[0].file.csv.defaultSeparator=,
bss.inventory.type[0].file.csv.fieldMapping.productSKU=COLUMN:ITEM_CODE
bss.inventory.type[0].file.csv.fieldMapping.quantity=COLUMN:QUANTITY
bss.inventory.type[0].file.csv.fieldMapping.transactionType=COLUMN:TRANSACTION_TYPE
bss.inventory.type[0].file.csv.fieldMapping.reservedForType=MAP_COLUMN:subInventoryToResellerType:SUBINVENTORY


#-------------------------------------------------------------------------------------
# Batch Order specific properties
#-------------------------------------------------------------------------------------

bss.order.defaultAllowedFor=NONE

bss.order.id=Generic
bss.order.allowedFor=${bss.order.defaultAllowedFor}
# Default scheduling type (when not provided in the RESP request)
bss.order.processor.schedType=immediate
# Scheduling time in spring cron format (when scheduling type is 'scheduled')
bss.order.processor.schedTime=0 0 1 * * ?
bss.order.processor.schedTypeDelay-sec=60
bss.order.processor.failOnError=false
bss.order.processor.chunkSize=1
# Number of chunks executed in parallel
# bss.order.processor.parallelChunkNb=10
bss.order.processor.maxRetryCount=3
#after what number of minutes (from the first retry) another retry should be considered
bss.order.processor.retryDelay=10
bss.order.file.uploadDescription=Order ${bss.order.id} import file
bss.order.file.supportedFormats=CSV,JSON
bss.order.file.format=CSV
bss.order.file.csv.freemarkerTemplate=order_import.ftl
bss.order.file.csv.header=Order_Type,Product_SKU,Buyer,Seller,Reserve_Type,Start_Serial,End_Serial,Return_Type,Return_Reason,Description
bss.order.file.csv.hasHeader=true
bss.order.file.csv.defaultSeparator=,
bss.order.file.csv.fieldMapping.buyerId=COLUMN:Buyer
bss.order.file.csv.fieldMapping.sellerId=COLUMN:Seller
bss.order.file.csv.fieldMapping.items_productSku=COLUMN:Product_SKU
bss.order.file.csv.fieldMapping.items_reserveType=COLUMN:Reserve_Type
bss.order.file.csv.fieldMapping.ranges_startSerial=COLUMN:Start_Serial
bss.order.file.csv.fieldMapping.ranges_endSerial=COLUMN:End_Serial
bss.order.file.csv.fieldMapping.orderType=COLUMN:Order_Type
bss.order.file.csv.fieldMapping.returnType=COLUMN:Return_Type
bss.order.file.csv.fieldMapping.returnReason=COLUMN:Return_Reason
bss.order.file.csv.fieldMapping.clientComment=COLUMN:Description



#-------------------------------------------------------------------------------------
# Batch Reverse Order specific properties
#-------------------------------------------------------------------------------------

bss.reverseorder.defaultAllowedFor=NONE

bss.reverseorder.id=Generic
bss.reverseorder.allowedFor=${bss.reverseorder.defaultAllowedFor}
# Default scheduling type (when not provided in the RESP request)
bss.reverseorder.processor.schedType=immediate
# Scheduling time in spring cron format (when scheduling type is 'scheduled')
bss.reverseorder.processor.schedTime=0 0 1 * * ?
bss.reverseorder.processor.schedTypeDelay-sec=60
bss.reverseorder.processor.failOnError=false
### Keep the chunkSize=1 because currently OMS only supports chunkSize=1
bss.reverseorder.processor.chunkSize=1
# Number of chunks executed in parallel
# bss.reverseorder.processor.parallelChunkNb=10
bss.reverseorder.processor.maxRetryCount=3
#after what number of minutes (from the first retry) another retry should be considered
bss.reverseorder.processor.retryDelay=10
bss.reverseorder.file.uploadDescription=Reverse order file
bss.reverseorder.file.supportedFormats=CSV,JSON
bss.reverseorder.file.format=CSV
bss.reverseorder.file.csv.freemarkerTemplate=order_reverse.ftl
bss.reverseorder.file.csv.header=OrderId,Description
bss.reverseorder.file.csv.hasHeader=true
bss.reverseorder.file.csv.defaultSeparator=,
bss.reverseorder.file.csv.fieldMapping.orderId=COLUMN:OrderId
bss.reverseorder.file.csv.fieldMapping.description=COLUMN:Description

#-------------------------------------------------------------------------------------
# Batch RateCard specific properties
#-------------------------------------------------------------------------------------

bss.ratecard.defaultAllowedFor=NONE
bss.ratecard.id=RateCard
bss.ratecard.allowedFor=${bss.ratecard.defaultAllowedFor}
# Default scheduling type (when not provided in the RESP request)
bss.ratecard.processor.schedType=immediate
# Scheduling time in spring cron format (when scheduling type is 'scheduled')
bss.ratecard.processor.schedTime=0 0 1 * * ?
bss.ratecard.processor.schedTypeDelay-sec=10
bss.ratecard.processor.failOnError=false
bss.ratecard.processor.chunkSize=10
# Number of chunks executed in parallel
# bss.ratecard.processor.parallelChunkNb=10
bss.ratecard.processor.maxRetryCount=3
#after what number of minutes (from the first retry) another retry should be considered
bss.ratecard.processor.retryDelay=10
bss.ratecard.file.uploadDescription=${bss.ratecard.id} import file
bss.ratecard.file.supportedFormats=CSV,JSON
bss.ratecard.file.format=CSV
bss.ratecard.file.csv.freemarkerTemplate=ratecard_import.ftl
bss.ratecard.file.csv.header=Pickup Location,Drop Location,Distance(Km),Minimum Capacity(KG),Maximum Capacity(KG),Rate,Logistic Type,SelfLoad,Flat Rate Capacity(KG),Additional Rate / KG,Status,Vendor,Priority Rate
bss.ratecard.file.csv.hasHeader=true
bss.ratecard.file.csv.defaultSeparator=,
bss.ratecard.file.csv.fieldMapping.vendor=COLUMN:Vendor
bss.ratecard.file.csv.fieldMapping.pickupLocation=COLUMN:Pickup Location
bss.ratecard.file.csv.fieldMapping.dropLocation=COLUMN:Drop Location
bss.ratecard.file.csv.fieldMapping.distance=COLUMN:Distance(Km)
bss.ratecard.file.csv.fieldMapping.status=COLUMN:Status
bss.ratecard.file.csv.fieldMapping.minKg=COLUMN:Minimum Capacity(KG)
bss.ratecard.file.csv.fieldMapping.maxKg=COLUMN:Maximum Capacity(KG)
bss.ratecard.file.csv.fieldMapping.charge=COLUMN:Rate
bss.ratecard.file.csv.fieldMapping.type=COLUMN:Logistic Type
bss.ratecard.file.csv.fieldMapping.flatUptoKg=COLUMN:Flat Rate Capacity(KG)
bss.ratecard.file.csv.fieldMapping.extraChargeAfterMaxKg=COLUMN:Additional Rate / KG
bss.ratecard.file.csv.fieldMapping.selfload=COLUMN:SelfLoad
bss.ratecard.file.csv.fieldMapping.priorityRate=COLUMN:Priority Rate


#-------------------------------------------------------------------------------------
# Batch CX specific properties
#-------------------------------------------------------------------------------------

bss.cx.defaultAllowedFor=NONE

bss.cx.id=Generic
bss.cx.allowedFor=${bss.cx.defaultAllowedFor}
bss.cx.processor.schedType=immediate
# Scheduling time in spring cron format (when scheduling type is 'scheduled')
bss.cx.processor.schedTime=0 0 1 * * ?
bss.cx.processor.schedTypeDelay-sec=30
bss.cx.processor.failOnError=false
#for cx use case the chunkSize must always be an even number
bss.cx.processor.chunkSize=10
# Number of chunks executed in parallel
# bss.cx.processor.parallelChunkNb=10
bss.cx.processor.maxRetryCount=3
#after what number of minutes (from the first retry) another retry should be considered
bss.cx.processor.retryDelay=10
bss.cx.file.uploadDescription=CX import file
bss.cx.file.supportedFormats=CSV
bss.cx.file.format=CSV
bss.cx.file.csv.freemarkerTemplate=inventory_update.ftl
bss.cx.file.csv.header=MSISDN,SIM,date,user
bss.cx.file.csv.hasHeader=false
bss.cx.file.csv.defaultSeparator=|
bss.cx.file.csv.fieldMapping.status=CONSTANT:CX sold


#-------------------------------------------------------------------------------------
# Batch Notification specific properties
#-------------------------------------------------------------------------------------

bss.bulknotification.id=Generic
# Not Allowed in import GUI
bss.bulknotification.allowedFor=
bss.bulknotification.processor.schedType=immediate
# Scheduling time in spring cron format (when scheduling type is 'scheduled')
bss.bulknotification.processor.schedTime=0 0 1 * * ?
bss.bulknotification.processor.schedTypeDelay-sec=30
bss.bulknotification.processor.failOnError=false
bss.bulknotification.processor.chunkSize=20
# Number of chunks executed in parallel
bss.bulknotification.processor.parallelChunkNb=5
bss.bulknotification.processor.maxRetryCount=3
#after what number of minutes (from the first retry) another retry should be considered
bss.bulknotification.processor.retryDelay=10
bss.bulknotification.file.uploadDescription=Notification import file
bss.bulknotification.file.supportedFormats=CSV
bss.bulknotification.file.format=CSV
bss.bulknotification.file.csv.freemarkerTemplate=notification.ftl
bss.bulknotification.file.csv.header=recipient
bss.bulknotification.file.csv.hasHeader=false
bss.bulknotification.file.csv.defaultSeparator=|


#-------------------------------------------------------------------------------------
# Batch Retry Notification specific properties
#-------------------------------------------------------------------------------------

bss.retrynotification.id=Generic
# Not Allowed in import GUI
bss.retrynotification.allowedFor=
bss.retrynotification.processor.schedType=immediate
# Scheduling time in spring cron format (when scheduling type is 'scheduled')
bss.retrynotification.processor.schedTime=0 0 1 * * ?
bss.retrynotification.processor.schedTypeDelay-sec=30
bss.retrynotification.processor.failOnError=false
# Only chunkSize=1 is supported
bss.retrynotification.processor.chunkSize=1
# Number of chunks executed in parallel
bss.retrynotification.processor.parallelChunkNb=10
bss.retrynotification.processor.maxRetryCount=3
#after what number of minutes (from the first retry) another retry should be considered
bss.retrynotification.processor.retryDelay=10
bss.retrynotification.file.uploadDescription="Retry notification import file"
bss.retrynotification.file.supportedFormats=CSV
bss.retrynotification.file.format=CSV
bss.retrynotification.file.csv.freemarkerTemplate=retry_notification.ftl
bss.retrynotification.file.csv.header=TDR
bss.retrynotification.file.csv.hasHeader=false
bss.retrynotification.file.csv.defaultSeparator=|

#-------------------------------------------------------------------------------------
# voucher for Generic
#-------------------------------------------------------------------------------------
bss.voucher.defaultAllowedFor=ALL
#Generic import for voucher is not allowed
bss.voucher.id=Generic
bss.voucher.allowedFor=NOT_ALLOWED
bss.voucher.operation=NO_OPERATION
bss.voucher.file.supportedFormats=CSV
bss.voucher.file.format=CSV
bss.voucher.file.csv.freemarkerTemplate=voucher_import.ftl
#-------------------------------------------------------------------------------------
# Batch files by elasticsearch
#-------------------------------------------------------------------------------------
# List of the es scanners (comma separated list. can be empty)
bss.esScanners=retryNotification
# 
bss.esScanners.retryNotification.enable=false
bss.esScanners.retryNotification.batchType=RetryNotification
#bss.esScanners.retryNotification.batchSubType=
bss.esScanners.retryNotification.uploadedBy=retryES
# to avoid sending multiple notification, this esScanner for retry notitication shall be scheduled 
# at an iterval longer then the interval needed to reach the notification manager 
# cumulated with interval neeeded by it to resend and update the status in notification_data_lake_*
bss.esScanners.retryNotification.cron.schedule=0 30 * * * ?
#JSON or CSV, depend of next processing
bss.esScanners.retryNotification.line.format=JSON
#mandatory for CSV line format:
#bss.esScanners.retryNotification.line.CSV.separator=|
bss.esScanners.retryNotification.batchesPerFile=10
#batch size must not exceed 10000
bss.esScanners.retryNotification.es.batchSize=10000
bss.esScanners.retryNotification.es.query={"bool": {"must": {"term": {"notificationmanager.notificationMessage.status": "retriable"}}, "should": [{"match": {"notificationmanager.notificationMessage.notificationType": "SMS"}}, {"match": {"notificationmanager.notificationMessage.notificationType": "EMAIL"}}], "minimum_should_match" : 1}}}
bss.esScanners.retryNotification.es.index=notification_data_lake_*


#-------------------------------------------------------------------------------------
# Batch files by FTP
#-------------------------------------------------------------------------------------
# List of the FTP directory scanners (comma separated list. can be empty)
bss.ftpFileScanners=productandvariant,stockAllocation

# upload stock allocation files
bss.ftpFileScanner.stockAllocation.enable=true
bss.ftpFileScanner.stockAllocation.batchType=Inventory
bss.ftpFileScanner.stockAllocation.batchSubType=Stock_Allocation
bss.ftpFileScanner.stockAllocation.uploadedBy=operator
bss.ftpFileScanner.stockAllocation.cron.schedule=0 0/5 * * * ?
bss.ftpFileScanner.stockAllocation.host=localhost
#For SFTP port will be 22
bss.ftpFileScanner.stockAllocation.port=22
#It will be either FTP or SFTP, by default it will be FTP
bss.ftpFileScanner.stockAllocation.protocol=SFTP
bss.ftpFileScanner.stockAllocation.username=root
bss.ftpFileScanner.stockAllocation.password=seamless
#bss.ftpFileScanner.stockAllocation.private_key.path=/opt/seamless/conf/batch-scheduling/id_rsa_test
#bss.ftpFileScanner.stockAllocation.preferred_authentications=password,publickey
#bss.ftpFileScanner.stockAllocation.passphrase=
bss.ftpFileScanner.stockAllocation.file.prefix=Stock_allocation
bss.ftpFileScanner.stockAllocation.directory.input=/var/seamless/batch-scheduling/inventory/stock-allocation/uploads
bss.ftpFileScanner.stockAllocation.directory.stage=/var/seamless/batch-scheduling/inventory/stock-allocation/uploads/stage
bss.ftpFileScanner.stockAllocation.directory.failed=/var/seamless/batch-scheduling/inventory/stock-allocation/uploads/validations-not-successful
bss.ftpFileScanner.stockAllocation.directory.processed=/var/seamless/batch-scheduling/inventory/stock-allocation/uploads/processed

# upload product+variant files
bss.ftpFileScanner.productandvariant.enable=true
bss.ftpFileScanner.productandvariant.batchType=Product
bss.ftpFileScanner.productandvariant.batchSubType=Product_And_Variant
bss.ftpFileScanner.productandvariant.uploadedBy=operator
bss.ftpFileScanner.productandvariant.cron.schedule=0 0/1 * * * ?
bss.ftpFileScanner.productandvariant.host=10.33.96.118
#For SFTP port will be 22
bss.ftpFileScanner.productandvariant.port=22
#It will be either FTP or SFTP, by default it will be FTP
bss.ftpFileScanner.productandvariant.protocol=SFTP
bss.ftpFileScanner.productandvariant.username=root
bss.ftpFileScanner.productandvariant.password=seamless
#bss.ftpFileScanner.productandvariant.private_key.path=/opt/seamless/conf/batch-scheduling/id_rsa_test
#bss.ftpFileScanner.productandvariant.preferred_authentications=password,publickey
#bss.ftpFileScanner.productandvariant.passphrase=
bss.ftpFileScanner.productandvariant.file.prefix=product
bss.ftpFileScanner.productandvariant.directory.input=/var/seamless/batch-scheduling/K8/product/uploads
bss.ftpFileScanner.productandvariant.directory.stage=/var/seamless/batch-scheduling/K8/product/uploads/stage
bss.ftpFileScanner.productandvariant.directory.failed=/var/seamless/batch-scheduling/K8/product/uploads/validations-not-successful
bss.ftpFileScanner.productandvariant.directory.processed=/var/seamless/batch-scheduling/K8/product/uploads/processed

# UpdateResellerParam Import files
#bss.ftpFileScanner.UpdateResellerParam_Import.enable=true
#bss.ftpFileScanner.UpdateResellerParam_Import.batchType=UpdateResellerParam
#bss.ftpFileScanner.UpdateResellerParam_Import.uploadedBy=operator
#bss.ftpFileScanner.UpdateResellerParam_Import.cron.schedule=0 0/1 * * * ?
#bss.ftpFileScanner.UpdateResellerParam_Import.host=localhost
#For SFTP port will be 22
#bss.ftpFileScanner.UpdateResellerParam_Import.port=22
#It will be either FTP or SFTP, by default it will be FTP
#bss.ftpFileScanner.UpdateResellerParam_Import.protocol=SFTP
#bss.ftpFileScanner.UpdateResellerParam_Import.username=root
#bss.ftpFileScanner.UpdateResellerParam_Import.password=seamless
#bss.ftpFileScanner.UpdateResellerParam_Import.file.prefix=ERP
#bss.ftpFileScanner.UpdateResellerParam_Import.directory.input=/root/updateResellerParam/uploads
#bss.ftpFileScanner.UpdateResellerParam_Import.directory.stage=/root/updateResellerParam/uploads/stage
#bss.ftpFileScanner.UpdateResellerParam_Import.directory.failed=/root/updateResellerParam/uploads/validations-not-successful
#bss.ftpFileScanner.UpdateResellerParam_Import.directory.processed=/root/updateResellerParam/uploads/processed

# ReceiptMethod Import files
#bss.ftpFileScanner.ReceiptMethod_Import.enable=true
#bss.ftpFileScanner.ReceiptMethod_Import.batchType=AssetReceiptMethod
#bss.ftpFileScanner.ReceiptMethod_Import.uploadedBy=operator
#bss.ftpFileScanner.ReceiptMethod_Import.cron.schedule=0 0/1 * * * ?
#bss.ftpFileScanner.ReceiptMethod_Import.host=localhost
#For SFTP port will be 22
#bss.ftpFileScanner.ReceiptMethod_Import.port=22
#It will be either FTP or SFTP, by default it will be FTP
#bss.ftpFileScanner.ReceiptMethod_Import.protocol=SFTP
#bss.ftpFileScanner.ReceiptMethod_Import.username=root
#bss.ftpFileScanner.ReceiptMethod_Import.password=seamless
#bss.ftpFileScanner.ReceiptMethod_Import.file.prefix=ERP
#bss.ftpFileScanner.ReceiptMethod_Import.directory.input=/root/receiptMethod/uploads
#bss.ftpFileScanner.ReceiptMethod_Import.directory.stage=/root/receiptMethod/uploads/stage
#bss.ftpFileScanner.ReceiptMethod_Import.directory.failed=/root/receiptMethod/uploads/validations-not-successful
#bss.ftpFileScanner.ReceiptMethod_Import.directory.processed=/root/receiptMethod/uploads/processed

# ReceiptMethod Import files
#bss.ftpFileScanner.DirectRetail_Import.enable=true
#bss.ftpFileScanner.DirectRetail_Import.batchType=DirectRetailing
#bss.ftpFileScanner.DirectRetail_Import.uploadedBy=operator
#bss.ftpFileScanner.DirectRetail_Import.cron.schedule=0 0/1 * * * ?
#bss.ftpFileScanner.DirectRetail_Import.host=localhost
#For SFTP port will be 22
#bss.ftpFileScanner.DirectRetail_Import.port=22
#It will be either FTP or SFTP, by default it will be FTP
#bss.ftpFileScanner.DirectRetail_Import.protocol=SFTP
#bss.ftpFileScanner.DirectRetail_Import.username=root
#bss.ftpFileScanner.DirectRetail_Import.password=seamless
#bss.ftpFileScanner.DirectRetail_Import.file.prefix=ERP
#bss.ftpFileScanner.DirectRetail_Import.directory.input=/root/directRetail/uploads
#bss.ftpFileScanner.DirectRetail_Import.directory.stage=/root/directRetail/uploads/stage
#bss.ftpFileScanner.DirectRetail_Import.directory.failed=/root/directRetail/uploads/validations-not-successful
#bss.ftpFileScanner.DirectRetail_Import.directory.processed=/root/directRetail/uploads/processed

#-------------------------------------------------------------------------------------
# Batch files by Local Directory Scanning
#-------------------------------------------------------------------------------------
# List of the Local directory scanners (comma separated list. can be empty)
bss.localFileScanners=AUTO_GRN,syncgpemployees,deactivateemployees
#bss.localFileScanners=resellerExtraParameters

# Update UpdateResellerExtraParam Inventory files
#bss.localFileScanner.resellerExtraParameters.enable=true
#bss.localFileScanner.resellerExtraParameters.batchType=UpdateResellerParam
#bss.localFileScanner.resellerExtraParameters.uploadedBy=operator
#bss.localFileScanner.resellerExtraParameters.cron.schedule=0 0 4 * * ?
#bss.localFileScanner.resellerExtraParameters.file.prefix=CRM
#bss.localFileScanner.resellerExtraParameters.directory.input=/home/admin/batch-scheduling/resellerExtraParameters/uploads
#bss.localFileScanner.resellerExtraParameters.directory.stage=/home/admin/batch-scheduling/resellerExtraParameters/uploads/stage
#bss.localFileScanner.resellerExtraParameters.directory.failed=/home/admin/batch-scheduling/resellerExtraParameters/uploads/validations-not-successful
#bss.localFileScanner.resellerExtraParameters.directory.processed=/home/admin/batch-scheduling/resellerExtraParameters/uploads/processed

# Update AssetMetaDataReceiptMethod Inventory files
#bss.localFileScanner.assetMetaDataReceiptMethod.enable=true
#bss.localFileScanner.assetMetaDataReceiptMethod.batchType=AssetReceiptMethod
#bss.localFileScanner.assetMetaDataReceiptMethod.uploadedBy=operator
#bss.localFileScanner.assetMetaDataReceiptMethod.cron.schedule=0 0/1 * * * ?
#bss.localFileScanner.assetMetaDataReceiptMethod.file.prefix=ERP
#bss.localFileScanner.assetMetaDataReceiptMethod.directory.input=/home/admin/batch-scheduling/receiptMethod/uploads
#bss.localFileScanner.assetMetaDataReceiptMethod.directory.stage=/home/admin/batch-scheduling/receiptMethod/uploads/stage
#bss.localFileScanner.assetMetaDataReceiptMethod.directory.failed=/home/admin/batch-scheduling/receiptMethod/uploads/validations-not-successful
#bss.localFileScanner.assetMetaDataReceiptMethod.directory.processed=/home/admin/batch-scheduling/receiptMethod/uploads/processed

# Update DirectRetailing Inventory files
#bss.localFileScanner.directRetailing.enable=true
#bss.localFileScanner.directRetailing.batchType=DirectRetailing
#bss.localFileScanner.directRetailing.uploadedBy=operator
#bss.localFileScanner.directRetailing.cron.schedule=0 0 4 * * ?
#bss.localFileScanner.directRetailing.file.prefix=ERP
#bss.localFileScanner.directRetailing.directory.input=/home/admin/batch-scheduling/directRetailing/uploads
#bss.localFileScanner.directRetailing.directory.stage=/home/admin/batch-scheduling/directRetailing/uploads/stage
#bss.localFileScanner.directRetailing.directory.failed=/home/admin/batch-scheduling/directRetailing/uploads/validations-not-successful
#bss.localFileScanner.directRetailing.directory.processed=/home/admin/batch-scheduling/directRetailing/uploads/processed

#-------------------------------------------------------------------------------------
# Batch Employee import file from server location
#-------------------------------------------------------------------------------------
bss.localFileScanner.syncgpemployees.enable=true
bss.localFileScanner.syncgpemployees.batchType=reseller
bss.localFileScanner.syncgpemployees.batchSubType=Users_ONBOARD_EMPLOYEES_Generic
bss.localFileScanner.syncgpemployees.uploadedBy=SEAMLESS_ADMIN
bss.localFileScanner.syncgpemployees.cron.schedule=0 */10 * ? * *
bss.localFileScanner.syncgpemployees.file.prefix=onboard_emp_
bss.localFileScanner.syncgpemployees.directory.input=/var/seamless/spool/tdr/gpHrPortal_Emp
bss.localFileScanner.syncgpemployees.directory.stage=/var/seamless/spool/tdr/gpHrPortal_Emp/stage
bss.localFileScanner.syncgpemployees.directory.failed=/var/seamless/spool/tdr/gpHrPortal_Emp/validations-not-successful
bss.localFileScanner.syncgpemployees.directory.processed=/var/seamless/spool/tdr/gpHrPortal_Emp/processed

#-------------------------------------------------------------------------------------
# Batch Employee Deactivate file from server location
#-------------------------------------------------------------------------------------
bss.localFileScanner.deactivateemployees.enable=true
bss.localFileScanner.deactivateemployees.batchType=reseller
bss.localFileScanner.deactivateemployees.batchSubType=Reseller_Deactivate
bss.localFileScanner.deactivateemployees.uploadedBy=SEAMLESS_ADMIN
bss.localFileScanner.deactivateemployees.cron.schedule=* */15 * ? * *
bss.localFileScanner.deactivateemployees.file.prefix=deboard_emp_
bss.localFileScanner.deactivateemployees.directory.input=/var/seamless/spool/tdr/gpHrPortal_Emp
bss.localFileScanner.deactivateemployees.directory.stage=/var/seamless/spool/tdr/gpHrPortal_Emp/stage
bss.localFileScanner.deactivateemployees.directory.failed=/var/seamless/spool/tdr/gpHrPortal_Emp/validations-not-successful
bss.localFileScanner.deactivateemployees.directory.processed=/var/seamless/spool/tdr/gpHrPortal_Emp/processed

#-------------------------------------------------------------------------------------
# Get Scheduled Batches, Get Import Info and Get Batch Info specific properties
#-------------------------------------------------------------------------------------
bss.history.visibleFor=Dealer,Sub Dealer
#bss.history.visibleFor=ALL

#-------------------------------------------------------------------------------------
# Audit feed config
#-------------------------------------------------------------------------------------
auditFeed.version=1
auditFeed.componentName=batch-scheduling
auditFeed.eventType=audit
# list of events can be either `INCLUDE` or `EXCLUDE`
audit.feed.list.type=EXCLUDE
# comma separated list
audit.feed.list.events=
auditFeed.freemarker.file.path=/opt/seamless/conf/batch-scheduling/auditfeeder/templates
auditFeed.default.template=batchscheduling_audit_feed.ftl

#-------------------------------------------------------------------------------------
# Data Feeder properties
#-------------------------------------------------------------------------------------
dataFeed.freemarker.file.path=/opt/seamless/conf/batch-scheduling/datafeeder/templates
threadpoolmanager.pools.dataFeed.targetId=com.seamless.common.data.dump.dataFeed
threadpoolmanager.pools.dataFeed.corePoolSize=25
threadpoolmanager.pools.dataFeed.maxPoolSize=40
threadpoolmanager.pools.dataFeed.keepAliveTime=60000
threadpoolmanager.pools.dataFeed.keepAliveTimeUnit=MILLISECONDS

dataFeed.version=1
#dataFeed.componentName=batchscheduling
dataFeed.componentName=bss
dataFeed.eventType=Report

#template.IMPORT_RATECARD=batchschedulingFeed_importGeneric.ftl
template.IMPORT_INVENTORY=batchschedulingFeed_importGeneric.ftl
#template.IMPORT_RESELLER=batchschedulingFeed_importGeneric.ftl
#template.IMPORT_RESELLER_USER=batchschedulingFeed_importGeneric.ftl
#template.IMPORT_ORDER=batchschedulingFeed_importGeneric.ftl
#template.IMPORT_REVERSEORDER=batchschedulingFeed_importGeneric.ftl
template.IMPORT_RESUBMIT=batchschedulingFeed_importGeneric.ftl
template.GET_IMPORT_INFO=batchschedulingFeed_importGeneric.ftl
template.GET_SERVICE_INFO=batchschedulingFeed_serviceInfo.ftl
template.GET_BATCH_INFO=batchschedulingFeed_batchInfo.ftl
template.GET_SCHEDULED_BATCHES=batchschedulingFeed_scheduledBatches.ftl
#template.IMPORT_TRANSACTION=batchschedulingFeed_importGeneric.ftl
template.UPDATE_IMPORT_TASK=batchschedulingFeed_updateImportTask.ftl
template.IMPORT_NOTIFICATION=batchschedulingFeed_importNotification.ftl
template.IMPORT_VOUCHER=batchschedulingFeed_importGeneric.ftl
template.IMPORT_DEMARCATION=batchschedulingFeed_importGeneric.ftl
template.IMPORT_STOCK_ALLOCATION=batchschedulingFeed_importGeneric.ftl
template.IMPORT_RESELLER_UPDATE_PARAM=batchschedulingFeed_importGeneric.ftl
template.CONTRACTS_PRICING_IMPORT=contracts_pricing_list_import.ftl
template.SERIALIZED_INVENTORY_IMPORT=inventory_import.ftl
template.NON_SERIALIZED_INVENTORY_IMPORT=inventory_import.ftl

#-------------------------------------------------------------------------------------
# Batch Transaction specific properties
#-------------------------------------------------------------------------------------

#requestHeader.O2C_SALE={"ref-prefix":"OT"}
#requestHeader.O2C_SALE_DIST={"ref-prefix":"OT"}
#requestHeader.O2C_SALE_RET={"ref-prefix":"OT"}
#requestHeader.O2C_FOC={"ref-prefix":"OT"}
#requestHeader.O2C_FOC_RET={"ref-prefix":"OT"}
#requestHeader.O2C_FOC_DIST={"ref-prefix":"OT"}
#requestHeader.TRANSACTION_REVERSAL={"ref-prefix":"BD"}
#requestHeader.C2C={"ref-prefix":"CT"}
#requestHeader.O2C_WITHDRAW={"ref-prefix":"OW"}
#requestHeader.C2C_WITHDRAW={"ref-prefix":"CW"}
#requestHeader.C2C_MULTIWALLET_SELF={"ref-prefix":"WT"}
#requestHeader.C2S_RECONCILIATION={"ref-prefix":"BD"}
#requestHeader.O2C_SALE_ESDIST={"ref-prefix":"OT"}
#requestHeader.O2C_SALE_EADIST={"ref-prefix":"OT"}
#requestHeader.O2C_SALE_SDIST={"ref-prefix":"OT"}
#requestHeader.O2C_FOC_ECDIST={"ref-prefix":"OT"}
#requestHeader.O2C_FOC_ESDIST={"ref-prefix":"OT"}
#requestHeader.O2C_FOC_EUDIST={"ref-prefix":"OT"}
#requestHeader.O2C_FOC_EADIST={"ref-prefix":"OT"}
#requestHeader.Pre2Pre_Reversal={"ref-prefix":"BD"}

bss.transaction.defaultAllowedFor=NONE

bss.transaction.id=Generic
bss.transaction.allowedFor=${bss.transaction.defaultAllowedFor}
# Default scheduling type (when not provided in the RESP request)
bss.transaction.processor.schedType=immediate
# Scheduling time in spring cron format (when scheduling type is 'scheduled')
bss.transaction.processor.schedTime=0 0 1 * * ?
bss.transaction.processor.schedTypeDelay-sec=60
bss.transaction.processor.failOnError=false
bss.transaction.processor.chunkSize=10
# Number of chunks executed in parallel
# bss.transaction.processor.parallelChunkNb=10
bss.transaction.processor.maxRetryCount=3
#after what number of minutes (from the first retry) another retry should be considered
bss.transaction.processor.retryDelay=10
#Indicates if an automatic retry must be performed in case we receive gateway errors from nginx
bss.transaction.processor.gatewayErrorsAutomaticRetry=true
#Indicates if an immediate retry must be performed in case of connection error (or gateway errors from nginx)
bss.transaction.processor.immediateRetry=true
bss.transaction.file.uploadDescription=transaction ${bss.transaction.id} import file
bss.transaction.file.supportedFormats=CSV,JSON
bss.transaction.file.format=CSV
bss.transaction.file.csv.freemarkerTemplate=transaction_o2c_foc_import.ftl
bss.transaction.file.csv.header=senderMsisdn,receiverMsisdn,amount,productSku
bss.transaction.file.csv.hasHeader=true
bss.transaction.file.csv.defaultSeparator=,
bss.transaction.file.csv.fieldMapping.senderId=COLUMN:senderMsisdn
bss.transaction.file.csv.fieldMapping.receiverId=COLUMN:receiverMsisdn
bss.transaction.file.csv.fieldMapping.value=COLUMN:amount
bss.transaction.file.csv.fieldMapping.productSKU=COLUMN:productSku
#left side fields need to match with txe request

#-------------------------------------------------------------------------------------
# UpdateResellerExtraParam properties
#-------------------------------------------------------------------------------------

bss.resellerupdateextraparam.defaultAllowedFor=ALL
bss.resellerupdateextraparam.id=UpdateResellerParam
bss.resellerupdateextraparam.processor.schedType=immediate
bss.resellerupdateextraparam.allowedFor=${bss.resellerupdateextraparam.defaultAllowedFor}
# Scheduling time in spring cron format (when scheduling type is 'scheduled')
bss.resellerupdateextraparam.processor.schedTime=0 0 1 * * ?
bss.resellerupdateextraparam.processor.schedTypeDelay-sec=60
bss.resellerupdateextraparam.processor.failOnError=false
bss.resellerupdateextraparam.processor.chunkSize=10
bss.resellerupdateextraparam.processor.maxRetryCount=3
#after what number of minutes (from the first retry) another retry should be considered
bss.resellerupdateextraparam.processor.retryDelay=10
bss.resellerupdateextraparam.file.uploadedBy=operator
bss.resellerupdateextraparam.file.uploadDescription=Reseller ${bss.resellerupdateextraparam.id} import file
bss.resellerupdateextraparam.file.supportedFormats=CSV,JSON
bss.resellerupdateextraparam.file.format=CSV
bss.resellerupdateextraparam.file.csv.freemarkerTemplate=reseller_update_extra_param.ftl
bss.resellerupdateextraparam.file.csv.header=CUSTOMER_NUMBER,PARTY_ID,CUST_ACCOUNT_ID,PARTY_SITE_ID,SITE_USE_ID,VA_NUMBER
bss.resellerupdateextraparam.file.csv.hasHeader=true
bss.resellerupdateextraparam.file.csv.defaultSeparator=,
bss.resellerupdateextraparam.file.csv.fieldMapping.resellerId=COLUMN:CUSTOMER_NUMBER
bss.resellerupdateextraparam.file.csv.fieldMapping.extraParam_partyId=COLUMN:PARTY_ID
bss.resellerupdateextraparam.file.csv.fieldMapping.extraParam_customerAccountId=COLUMN:CUST_ACCOUNT_ID
bss.resellerupdateextraparam.file.csv.fieldMapping.extraParam_partySiteId=COLUMN:PARTY_SITE_ID
bss.resellerupdateextraparam.file.csv.fieldMapping.extraParam_siteUseId=COLUMN:SITE_USE_ID
bss.resellerupdateextraparam.file.csv.fieldMapping.extraParam_vaNumber=COLUMN:VA_NUMBER

#-------------------------------------------------------------------------------------
# AssetReceiptMethod properties
#-------------------------------------------------------------------------------------
bss.assetmetadatareceiptmethod.defaultAllowedFor=ALL
bss.assetmetadatareceiptmethod.id=AssetReceiptMethod
bss.assetmetadatareceiptmethod.processor.schedType=immediate
bss.assetmetadatareceiptmethod.allowedFor=${bss.assetmetadatareceiptmethod.defaultAllowedFor}
# Scheduling time in spring cron format (when scheduling type is 'scheduled')
bss.assetmetadatareceiptmethod.processor.schedTime=0 0 1 * * ?
bss.assetmetadatareceiptmethod.processor.schedTypeDelay-sec=60
bss.assetmetadatareceiptmethod.processor.failOnError=false
bss.assetmetadatareceiptmethod.processor.chunkSize=10
bss.assetmetadatareceiptmethod.processor.maxRetryCount=3
#after what number of minutes (from the first retry) another retry should be considered
bss.assetmetadatareceiptmethod.processor.retryDelay=10
bss.assetmetadatareceiptmethod.file.uploadedBy=operator
bss.assetmetadatareceiptmethod.file.uploadDescription=Reseller ${bss.assetmetadatareceiptmethod.id} import file
bss.assetmetadatareceiptmethod.file.supportedFormats=CSV,JSON
bss.assetmetadatareceiptmethod.file.format=CSV
bss.assetmetadatareceiptmethod.file.csv.freemarkerTemplate=asset_metaData_receipt_method.ftl
bss.assetmetadatareceiptmethod.file.csv.header=ID,DMS_BANKNAME,FUSION_BANKNAME,BANK_ACCOUNT_NUM,RECEIPT_METHOD
bss.assetmetadatareceiptmethod.file.csv.hasHeader=true
bss.assetmetadatareceiptmethod.file.csv.defaultSeparator=,
bss.assetmetadatareceiptmethod.file.csv.fieldMapping.id=COLUMN:ID
bss.assetmetadatareceiptmethod.file.csv.fieldMapping.dmsBankName=COLUMN:DMS_BANKNAME
bss.assetmetadatareceiptmethod.file.csv.fieldMapping.extraParam_fusionBank=COLUMN:FUSION_BANKNAME
bss.assetmetadatareceiptmethod.file.csv.fieldMapping.extraParam_bankAccountNumber=COLUMN:BANK_ACCOUNT_NUM
bss.assetmetadatareceiptmethod.file.csv.fieldMapping.extraParam_receiptMethod=COLUMN:RECEIPT_METHOD
#-------------------------------------------------------------------------------------
# assetmetadata POS_TYPE properties
#-------------------------------------------------------------------------------------
bss.assetmetadata.defaultAllowedFor=ALL
bss.assetmetadata.id=POS_TYPE
bss.assetmetadata.processor.schedType=immediate
bss.assetmetadata.allowedFor=${bss.assetmetadata.defaultAllowedFor}
bss.assetmetadata.processor.schedTime=0 0/1 * * * ?
bss.assetmetadata.processor.schedTypeDelay-sec=60
bss.assetmetadata.processor.failOnError=false
bss.assetmetadata.processor.chunkSize=10
bss.assetmetadata.processor.maxRetryCount=3
bss.assetmetadata.processor.retryDelay=10
bss.assetmetadata.file.uploadedBy=operator
bss.assetmetadata.file.uploadDescription=Reseller ${bss.assetmetadata.id} import file
bss.assetmetadata.file.supportedFormats=CSV,JSON
bss.assetmetadata.file.format=CSV
bss.assetmetadata.file.csv.freemarkerTemplate=asset_metaData_pos_type.ftl
bss.assetmetadata.file.csv.header=ID,NAME,CATEGORY_ID,CATEGORY_NAME,CATEGORY_VALUE
bss.assetmetadata.file.csv.hasHeader=true
bss.assetmetadata.file.csv.defaultSeparator=,
bss.assetmetadata.file.csv.fieldMapping.id=COLUMN:ID
bss.assetmetadata.file.csv.fieldMapping.name=COLUMN:NAME
bss.assetmetadata.file.csv.fieldMapping.extraParam_CATEGORY_ID=COLUMN:CATEGORY_ID
bss.assetmetadata.file.csv.fieldMapping.extraParam_CATEGORY_NAME=COLUMN:CATEGORY_NAME
bss.assetmetadata.file.csv.fieldMapping.extraParam_CATEGORY_VALUE=COLUMN:CATEGORY_VALUE
#-------------------------------------------------------------------------------------
# assetmetadata POS_CATEGORY properties
#-------------------------------------------------------------------------------------
bss.assetmetadata.type[0].defaultAllowedFor=ALL
bss.assetmetadata.type[0].id=POS_CATEGORY
bss.assetmetadata.type[0].processor.schedType=immediate
bss.assetmetadata.type[0].allowedFor=${bss.assetmetadata.defaultAllowedFor}
bss.assetmetadata.type[0].processor.schedTime=0 0/1 * * * ?
bss.assetmetadata.type[0].processor.schedTypeDelay-sec=60
bss.assetmetadata.type[0].processor.failOnError=false
bss.assetmetadata.type[0].processor.chunkSize=10
bss.assetmetadata.type[0].processor.maxRetryCount=3
bss.assetmetadata.type[0].processor.retryDelay=10
bss.assetmetadata.type[0].file.uploadedBy=operator
bss.assetmetadata.type[0].file.uploadDescription=Reseller ${bss.assetmetadata.type[1].id} import file
bss.assetmetadata.type[0].file.supportedFormats=CSV,JSON
bss.assetmetadata.type[0].file.format=CSV
bss.assetmetadata.type[0].file.csv.freemarkerTemplate=asset_metaData_pos_category.ftl
bss.assetmetadata.type[0].file.csv.header=ID,NAME,PARENT_ID,POS_TYPE_ID,POS_TYPE_NAME
bss.assetmetadata.type[0].file.csv.hasHeader=true
bss.assetmetadata.type[0].file.csv.defaultSeparator=,
bss.assetmetadata.type[0].file.csv.fieldMapping.id=COLUMN:ID
bss.assetmetadata.type[0].file.csv.fieldMapping.name=COLUMN:NAME
bss.assetmetadata.type[0].file.csv.fieldMapping.parentId=COLUMN:PARENT_ID
bss.assetmetadata.type[0].file.csv.fieldMapping.extraParam_POS_TYPE_ID=COLUMN:POS_TYPE_ID
bss.assetmetadata.type[0].file.csv.fieldMapping.extraParam_POS_TYPE_NAME=COLUMN:POS_TYPE_NAME
#-------------------------------------------------------------------------------------
# assetmetadata POS_VALUE_CLASS properties
#-------------------------------------------------------------------------------------
bss.assetmetadata.type[1].defaultAllowedFor=ALL
bss.assetmetadata.type[1].id=POS_VALUE_CLASS
bss.assetmetadata.type[1].processor.schedType=immediate
bss.assetmetadata.type[1].allowedFor=${bss.assetmetadata.defaultAllowedFor}
bss.assetmetadata.type[1].processor.schedTime=0 0/1 * * * ?
bss.assetmetadata.type[1].processor.schedTypeDelay-sec=60
bss.assetmetadata.type[1].processor.failOnError=false
bss.assetmetadata.type[1].processor.chunkSize=10
bss.assetmetadata.type[1].processor.maxRetryCount=3
bss.assetmetadata.type[1].processor.retryDelay=10
bss.assetmetadata.type[1].file.uploadedBy=operator
bss.assetmetadata.type[1].file.uploadDescription=Reseller ${bss.assetmetadata.type[1].id} import file
bss.assetmetadata.type[1].file.supportedFormats=CSV,JSON
bss.assetmetadata.type[1].file.format=CSV
bss.assetmetadata.type[1].file.csv.freemarkerTemplate=asset_metaData_pos_value_class.ftl
bss.assetmetadata.type[1].file.csv.header=ID,NAME,POS_VALUE_CLASS
bss.assetmetadata.type[1].file.csv.hasHeader=true
bss.assetmetadata.type[1].file.csv.defaultSeparator=,
bss.assetmetadata.type[1].file.csv.fieldMapping.id=COLUMN:ID
bss.assetmetadata.type[1].file.csv.fieldMapping.name=COLUMN:NAME
bss.assetmetadata.type[1].file.csv.fieldMapping.extraParam_POS_VALUE_CLASS=COLUMN:POS_VALUE_CLASS
#-------------------------------------------------------------------------------------
# assetmetadata SERVICE_TYPE properties
#-------------------------------------------------------------------------------------
bss.assetmetadata.type[2].defaultAllowedFor=ALL
bss.assetmetadata.type[2].id=SERVICE_TYPE
bss.assetmetadata.type[2].processor.schedType=immediate
bss.assetmetadata.type[2].allowedFor=${bss.assetmetadata.defaultAllowedFor}
bss.assetmetadata.type[2].processor.schedTime=0 0/1 * * * ?
bss.assetmetadata.type[2].processor.schedTypeDelay-sec=60
bss.assetmetadata.type[2].processor.failOnError=false
bss.assetmetadata.type[2].processor.chunkSize=10
bss.assetmetadata.type[2].processor.maxRetryCount=3
bss.assetmetadata.type[2].processor.retryDelay=10
bss.assetmetadata.type[2].file.uploadedBy=operator
bss.assetmetadata.type[2].file.uploadDescription=Reseller ${bss.assetmetadata.type[2].id} import file
bss.assetmetadata.type[2].file.supportedFormats=CSV,JSON
bss.assetmetadata.type[2].file.format=CSV
bss.assetmetadata.type[2].file.csv.freemarkerTemplate=asset_metaData_service_type.ftl
bss.assetmetadata.type[2].file.csv.header=ID,NAME,PARTNER_SERVICE_TYPE_KEY
bss.assetmetadata.type[2].file.csv.hasHeader=true
bss.assetmetadata.type[2].file.csv.defaultSeparator=,
bss.assetmetadata.type[2].file.csv.fieldMapping.id=COLUMN:ID
bss.assetmetadata.type[2].file.csv.fieldMapping.name=COLUMN:NAME
bss.assetmetadata.type[2].file.csv.fieldMapping.extraParam_PARTNER_SERVICE_TYPE_KEY=COLUMN:PARTNER_SERVICE_TYPE_KEY
#-------------------------------------------------------------------------------------
# assetmetadata BANK properties
#-------------------------------------------------------------------------------------
bss.assetmetadata.type[3].defaultAllowedFor=ALL
bss.assetmetadata.type[3].id=BANK
bss.assetmetadata.type[3].processor.schedType=immediate
bss.assetmetadata.type[3].allowedFor=${bss.assetmetadata.defaultAllowedFor}
bss.assetmetadata.type[3].processor.schedTime=0 0/1 * * * ?
bss.assetmetadata.type[3].processor.schedTypeDelay-sec=60
bss.assetmetadata.type[3].processor.failOnError=false
bss.assetmetadata.type[3].processor.chunkSize=10
bss.assetmetadata.type[3].processor.maxRetryCount=3
bss.assetmetadata.type[3].processor.retryDelay=10
bss.assetmetadata.type[3].file.uploadedBy=operator
bss.assetmetadata.type[3].file.uploadDescription=Reseller ${bss.assetmetadata.type[3].id} import file
bss.assetmetadata.type[3].file.supportedFormats=CSV,JSON
bss.assetmetadata.type[3].file.format=CSV
bss.assetmetadata.type[3].file.csv.freemarkerTemplate=asset_metaData_bank.ftl
bss.assetmetadata.type[3].file.csv.header=ID,NAME,BANK_CODE,ADDRESS,PHONE_NUMBER,AUTO_DEBIT_ACCEPTANCE,OPERATOR_BANK,EFFECTIVE_DATE,EXPIRY_DATE
bss.assetmetadata.type[3].file.csv.hasHeader=true
bss.assetmetadata.type[3].file.csv.defaultSeparator=,
bss.assetmetadata.type[3].file.csv.fieldMapping.id=COLUMN:ID
bss.assetmetadata.type[3].file.csv.fieldMapping.name=COLUMN:NAME
bss.assetmetadata.type[3].file.csv.fieldMapping.code=COLUMN:BANK_CODE
bss.assetmetadata.type[3].file.csv.fieldMapping.availableFrom=COLUMN:EFFECTIVE_DATE
bss.assetmetadata.type[3].file.csv.fieldMapping.availableUntil=COLUMN:EXPIRY_DATE
bss.assetmetadata.type[3].file.csv.fieldMapping.extraParam_ADDRESS=COLUMN:ADDRESS
bss.assetmetadata.type[3].file.csv.fieldMapping.extraParam_PHONE_NUMBER=COLUMN:PHONE_NUMBER
bss.assetmetadata.type[3].file.csv.fieldMapping.extraParam_AUTO_DEBIT_ACCEPTANCE=COLUMN:AUTO_DEBIT_ACCEPTANCE
bss.assetmetadata.type[3].file.csv.fieldMapping.extraParam_OPERATOR_BANK=COLUMN:OPERATOR_BANK
#-------------------------------------------------------------------------------------
# assetmetadata BRANCH properties
#-------------------------------------------------------------------------------------
bss.assetmetadata.type[4].defaultAllowedFor=ALL
bss.assetmetadata.type[4].id=BRANCH
bss.assetmetadata.type[4].processor.schedType=immediate
bss.assetmetadata.type[4].allowedFor=${bss.assetmetadata.defaultAllowedFor}
bss.assetmetadata.type[4].processor.schedTime=0 0/1 * * * ?
bss.assetmetadata.type[4].processor.schedTypeDelay-sec=60
bss.assetmetadata.type[4].processor.failOnError=false
bss.assetmetadata.type[4].processor.chunkSize=10
bss.assetmetadata.type[4].processor.maxRetryCount=3
bss.assetmetadata.type[4].processor.retryDelay=10
bss.assetmetadata.type[4].file.uploadedBy=operator
bss.assetmetadata.type[4].file.uploadDescription=Reseller ${bss.assetmetadata.type[4].id} import file
bss.assetmetadata.type[4].file.supportedFormats=CSV,JSON
bss.assetmetadata.type[4].file.format=CSV
bss.assetmetadata.type[4].file.csv.freemarkerTemplate=asset_metaData_branch.ftl
bss.assetmetadata.type[4].file.csv.header=ID,NAME,PARENT_ID,BANK_NAME,EFFECTIVE_DATE,EXPIRY_DATE,BRANCH_CODE,BRANCH_DISTRICT,BANK_ROUTE_NO
bss.assetmetadata.type[4].file.csv.hasHeader=true
bss.assetmetadata.type[4].file.csv.defaultSeparator=,
bss.assetmetadata.type[4].file.csv.fieldMapping.id=COLUMN:ID
bss.assetmetadata.type[4].file.csv.fieldMapping.name=COLUMN:NAME
bss.assetmetadata.type[4].file.csv.fieldMapping.parentId=COLUMN:PARENT_ID
bss.assetmetadata.type[4].file.csv.fieldMapping.availableFrom=COLUMN:EFFECTIVE_DATE
bss.assetmetadata.type[4].file.csv.fieldMapping.availableUntil=COLUMN:EXPIRY_DATE
bss.assetmetadata.type[4].file.csv.fieldMapping.code=COLUMN:BRANCH_CODE
bss.assetmetadata.type[4].file.csv.fieldMapping.extraParam_BANK_NAME=COLUMN:BANK_NAME
bss.assetmetadata.type[4].file.csv.fieldMapping.extraParam_BRANCH_DISTRICT=COLUMN:BRANCH_DISTRICT
bss.assetmetadata.type[4].file.csv.fieldMapping.extraParam_BANK_ROUTE_NO=COLUMN:BANK_ROUTE_NO

#-------------------------------------------------------------------------------------
# DirectRetailing properties
#-------------------------------------------------------------------------------------
bss.directRetailing.defaultAllowedFor=ALL
bss.directRetailing.id=DirectRetailing
bss.directRetailing.processor.schedType=immediate
bss.directRetailing.allowedFor=${bss.directRetailing.defaultAllowedFor}
# Scheduling time in spring cron format (when scheduling type is 'scheduled')
bss.directRetailing.processor.schedTime=0 0/1 * * * ?
bss.directRetailing.processor.schedTypeDelay-sec=60
bss.directRetailing.processor.failOnError=false
bss.directRetailing.processor.chunkSize=10
bss.directRetailing.processor.maxRetryCount=3
#after what number of minutes (from the first retry) another retry should be considered
bss.directRetailing.processor.retryDelay=10
bss.directRetailing.file.uploadedBy=operator
bss.directRetailing.file.uploadDescription=Reseller ${bss.directRetailing.id} import file
bss.directRetailing.file.supportedFormats=CSV,JSON
bss.directRetailing.file.format=CSV
bss.directRetailing.file.csv.freemarkerTemplate=reseller_direct_retailing.ftl
bss.directRetailing.file.csv.header=CUSTOMER_NUMBER,Bkash,Nagad,Tap
bss.directRetailing.file.csv.hasHeader=true
bss.directRetailing.file.csv.defaultSeparator=,
bss.directRetailing.file.csv.fieldMapping.resellerId=COLUMN:CUSTOMER_NUMBER
bss.directRetailing.file.csv.fieldMapping.channel_Bkash=COLUMN:Bkash
bss.directRetailing.file.csv.fieldMapping.channel_Nagad=COLUMN:Nagad
bss.directRetailing.file.csv.fieldMapping.channel_Tap=COLUMN:Tap

#-------------------------------------------------------------------------------------
# Reseller BTS_MAPPING properties
#-------------------------------------------------------------------------------------
bss.directRetailing.type[0].defaultAllowedFor=ALL
bss.directRetailing.type[0].id=BTS_MAPPING
bss.directRetailing.type[0].processor.schedType=immediate
bss.directRetailing.type[0].allowedFor=${bss.directRetailing.defaultAllowedFor}
bss.directRetailing.type[0].processor.schedTime=0 0/1 * * * ?
bss.directRetailing.type[0].processor.schedTypeDelay-sec=60
bss.directRetailing.type[0].processor.failOnError=false
bss.directRetailing.type[0].processor.chunkSize=10
bss.directRetailing.type[0].processor.maxRetryCount=3
bss.directRetailing.type[0].processor.retryDelay=10
bss.directRetailing.type[0].file.uploadedBy=operator
bss.directRetailing.type[0].file.uploadDescription=Reseller ${bss.directRetailing.type[1].id} import file
bss.directRetailing.type[0].file.supportedFormats=CSV,JSON
bss.directRetailing.type[0].file.format=CSV
bss.directRetailing.type[0].file.csv.freemarkerTemplate=reseller_bts_mapping.ftl
bss.directRetailing.type[0].file.csv.header=rtrId,assignedBTS
bss.directRetailing.type[0].file.csv.hasHeader=true
bss.directRetailing.type[0].file.csv.defaultSeparator=|
bss.directRetailing.type[0].file.csv.fieldMapping.resellerId=COLUMN:rtrId
bss.directRetailing.type[0].file.csv.fieldMapping.extraParam_assignedBTS=COLUMN:assignedBTS

#-------------------------------------------------------------------------------------
# Batch Scheduling for campaign targets
#-------------------------------------------------------------------------------------

bss.campaigntargets.defaultAllowedFor=NONE

bss.campaigntargets.id=campaignTargets
bss.campaigntargets.allowedFor=${bss.campaigntargets.defaultAllowedFor}
# Default scheduling type (when not provided in the RESP request)
bss.campaigntargets.processor.schedType=immediate
# Scheduling time in spring cron format (when scheduling type is 'scheduled')
bss.campaigntargets.processor.schedTime=0 0 1 * * ?
bss.campaigntargets.processor.schedTypeDelay-sec=60
bss.campaigntargets.processor.failOnError=false
bss.campaigntargets.processor.chunkSize=10
bss.campaigntargets.processor.maxRetryCount=3
#after what number of minutes (from the first retry) another retry should be considered
bss.campaigntargets.processor.retryDelay=10
bss.campaigntargets.file.uploadDescription=campaigntargets ${bss.campaigntargets.id} import file
bss.campaigntargets.file.supportedFormats=CSV,JSON
bss.campaigntargets.file.format=CSV
bss.campaigntargets.file.csv.freemarkerTemplate=campaign_targets.ftl
bss.campaigntargets.file.csv.header=resellerMSISDN,campaignId,kpiName,event,target
bss.campaigntargets.file.csv.hasHeader=true
bss.campaigntargets.file.csv.defaultSeparator=,
bss.campaigntargets.file.csv.fieldMapping.resellerMSISDN=COLUMN:resellerMSISDN
#bss.campaigntargets.file.csv.fieldMapping.sellerId=COLUMN:Seller
bss.campaigntargets.file.csv.fieldMapping.campaignId=COLUMN:campaignId
bss.campaigntargets.file.csv.fieldMapping.kpiName=COLUMN:kpiName
bss.campaigntargets.file.csv.fieldMapping.event=COLUMN:event
bss.campaigntargets.file.csv.fieldMapping.target=COLUMN:target

#-------------------------------------------------------------------------------------
# Inventory Import:
#-------------------------------------------------------------------------------------
############# Import auto-grn Inventory files#############
bss.localFileScanner.AUTO_GRN.enable=true
bss.localFileScanner.AUTO_GRN.batchType=Inventory
bss.localFileScanner.AUTO_GRN.batchSubType=AUTO_GRN
bss.localFileScanner.AUTO_GRN.uploadedBy=operator
bss.localFileScanner.AUTO_GRN.cron.schedule=0 * * * * *
bss.localFileScanner.AUTO_GRN.file.prefix=GRNFile
bss.localFileScanner.AUTO_GRN.directory.input=/home/admin/batch-scheduling/inventory/auto-grn/uploads
bss.localFileScanner.AUTO_GRN.directory.stage=/home/admin/batch-scheduling/inventory/auto-grn/uploads/stage
bss.localFileScanner.AUTO_GRN.directory.failed=/home/admin/batch-scheduling/inventory/auto-grn/uploads/validations-not-successful
bss.localFileScanner.AUTO_GRN.directory.processed=/home/admin/batch-scheduling/inventory/auto-grn/uploads/processed


bss.inventory.type[1].id=AUTO_GRN
bss.inventory.type[1].allowedFor=${bss.inventory.defaultAllowedFor}
bss.inventory.type[1].processor.schedType=scheduled
# Scheduling time in spring cron format (when scheduling type is 'scheduled')
bss.inventory.type[1].processor.schedTime=0 * * * * *
bss.inventory.type[1].processor.schedTypeDelay-sec=30
bss.inventory.type[1].processor.failOnError=true
# fallbackOnError parameter is meaningful only when failOnError=true.
# Set fallbackOnError=true to call the external system to revert the import in case of error (default behavior)
# Set fallbackOnError=false to disable fallback in case of error (for backward compatibility)
bss.inventory.type[1].processor.fallbackOnError=true
bss.inventory.type[1].processor.chunkSize=100
# Number of chunks executed in parallel
# bss.inventory.type[1].processor.parallelChunkNb=10
bss.inventory.type[1].file.uploadDescription=Inventory ${bss.inventory.type[1].id} import file
bss.inventory.type[1].file.supportedFormats=CSV
bss.inventory.type[1].file.format=CSV
bss.inventory.type[1].file.csv.freemarkerTemplate=inventory_import_not_empty_data.ftl
bss.inventory.type[1].file.csv.header=ProductSKU,Serial,Additional_Reference_No,Quantity,Status,Owner,OrderId
bss.inventory.type[1].file.csv.hasHeader=true
bss.inventory.type[1].file.csv.defaultSeparator=,
bss.inventory.type[1].file.csv.fieldMapping.productSKU=COLUMN:ProductSKU
bss.inventory.type[1].file.csv.fieldMapping.serialNo=COLUMN:Serial
bss.inventory.type[1].file.csv.fieldMapping.quantity=COLUMN:Quantity
bss.inventory.type[1].file.csv.fieldMapping.state=COLUMN:Status
bss.inventory.type[1].file.csv.fieldMapping.owner=COLUMN:Owner
bss.inventory.type[1].file.csv.fieldMapping.orderId=COLUMN:OrderId
bss.inventory.type[1].file.csv.fieldMapping.batchId=SYSTEM:batchId
bss.inventory.type[1].file.csv.fieldMapping.data_additional_reference_no=COLUMN:Additional_Reference_No

#-------------------------------------------------------------------------------------
# Stock Allocation Generic
#-------------------------------------------------------------------------------------
bss.stockallocation.defaultAllowedFor=ALL
#Generic import for stock allocation is not allowed
bss.stockallocation.id=Generic
bss.stockallocation.allowedFor=NOT_ALLOWED
bss.stockallocation.operation=NO_OPERATION
bss.stockallocation.file.supportedFormats=CSV
bss.stockallocation.file.format=CSV
bss.stockallocation.file.csv.freemarkerTemplate=stock_allocation_import.ftl
bss.stockallocation.file.fieldValidationRegExp={\
    'Start Date':'^(0[1-9]|[12][0-9]|3[01])\\/(0[1-9]|1[012])\\/\\d{4}\\s([01]\\d|2[0-3]):([0-5]\\d):([0-5]\\d)$' ,\
    'End Date':'^(0[1-9]|[12][0-9]|3[01])\\/(0[1-9]|1[012])\\/\\d{4}\\s([01]\\d|2[0-3]):([0-5]\\d):([0-5]\\d)$' ,\
    'Payment Refund Date':'^(0[1-9]|[12][0-9]|3[01])\\/(0[1-9]|1[012])\\/\\d{4}\\s([01]\\d|2[0-3]):([0-5]\\d):([0-5]\\d)$' ,\
    'Old Credit Value':'^[\\d]*[\\.]?[\\d]*$' ,\
    'New Credit Value':'^[\\d]*[\\.]?[\\d]*$' \
}
bss.stockallocation.file.numeric.fieldValidationRegExp={\
    'Old Cash Value':'^[\\d]*[\\.]?[\\d]*$' ,\
    'New Cash Value':'^[\\d]*[\\.]?[\\d]*$' \
 }

#-------------------------------------------------------------------------------------
# Stock Allocation CASH
#-------------------------------------------------------------------------------------
bss.stockallocation.type[0].id=STOCK_ALLOCATION_CASH
bss.stockallocation.type[0].allowedFor=${bss.stockallocation.defaultAllowedFor}
bss.stockallocation.type[0].operation=CASH_ALLOCATION
# Comma separated list (can be empty). Two batches having the same tag will not be executed at the same time (no overlapping execution)
bss.stockallocation.type[0].processor.exclusiveTags=allocation
bss.stockallocation.type[0].processor.schedType=immediate
# Scheduling time in spring cron format (when scheduling type is 'scheduled')
bss.stockallocation.type[0].processor.schedTime=0 0 1 * * ?
bss.stockallocation.type[0].processor.schedTypeDelay-sec=30
bss.stockallocation.type[0].processor.failOnError=true
# fallbackOnError parameter is meaningful only when failOnError=true.
# Set fallbackOnError=true to call the external system to revert the import in case of error (default behavior)
# Set fallbackOnError=false to disable fallback in case of error (for backward compatibility)
bss.stockallocation.type[0].processor.fallbackOnError=true
bss.stockallocation.type[0].processor.chunkSize=10
# Number of chunks executed in parallel
# bss.stockallocation.type[0].processor.parallelChunkNb=10
bss.stockallocation.type[0].file.uploadDescription=Stock allocation ${bss.stockallocation.type[0].id} batch file
bss.stockallocation.type[0].file.supportedFormats=CSV
bss.stockallocation.type[0].file.format=CSV
bss.stockallocation.type[0].file.csv.freemarkerTemplate=stock_allocation_import.ftl
bss.stockallocation.type[0].file.csv.header=Partner Code,Allocation Product Item,Quota UOM,Old Cash Value,New Cash Value
bss.stockallocation.type[0].file.csv.fieldMapping.resellerId=COLUMN:Partner Code
bss.stockallocation.type[0].file.csv.fieldMapping.productSKU=COLUMN:Allocation Product Item
bss.stockallocation.type[0].file.csv.fieldMapping.quotaUOM=COLUMN:Quota UOM
bss.stockallocation.type[0].file.csv.fieldMapping.quotaValue=COLUMN:New Cash Value
bss.stockallocation.type[0].file.csv.fieldMapping.quotaType=CONSTANT:CASH
bss.stockallocation.type[0].file.csv.hasHeader=true
bss.stockallocation.type[0].file.csv.defaultSeparator=,
bss.stockallocation.type[0].file.csv.fieldValidationRegExp=${bss.stockallocation.file.numeric.fieldValidationRegExp}
#-------------------------------------------------------------------------------------
# Stock Allocation CREDIT
#-------------------------------------------------------------------------------------
bss.stockallocation.type[1].id=STOCK_ALLOCATION_CREDIT
bss.stockallocation.type[1].allowedFor=${bss.stockallocation.defaultAllowedFor}
bss.stockallocation.type[1].operation=CREDIT_ALLOCATION
bss.stockallocation.type[1].processor.schedType=immediate
# Comma separated list (can be empty). Two batches having the same tag will not be executed at the same time (no overlapping execution)
bss.stockallocation.type[1].processor.exclusiveTags=allocation
# Scheduling time in spring cron format (when scheduling type is 'scheduled')
bss.stockallocation.type[1].processor.schedTime=0 0 1 * * ?
bss.stockallocation.type[1].processor.schedTypeDelay-sec=30
bss.stockallocation.type[1].processor.failOnError=true
# fallbackOnError parameter is meaningful only when failOnError=true.
# Set fallbackOnError=true to call the external system to revert the import in case of error (default behavior)
# Set fallbackOnError=false to disable fallback in case of error (for backward compatibility)
bss.stockallocation.type[1].processor.fallbackOnError=true
bss.stockallocation.type[1].processor.chunkSize=10
# Number of chunks executed in parallel
# bss.stockallocation.type[1].processor.parallelChunkNb=10
bss.stockallocation.type[1].file.uploadDescription=Stock allocation ${bss.stockallocation.type[1].id} batch file
bss.stockallocation.type[1].file.supportedFormats=CSV
bss.stockallocation.type[1].file.format=CSV
bss.stockallocation.type[1].file.csv.freemarkerTemplate=stock_allocation_import.ftl
bss.stockallocation.type[1].file.csv.header=Partner Code,Allocation Product Item,Quota UOM,Old Credit Value,New Credit Value,Start Date,End Date,Payment Refund Date
bss.stockallocation.type[1].file.csv.fieldMapping.resellerId=COLUMN:Partner Code
bss.stockallocation.type[1].file.csv.fieldMapping.productSKU=COLUMN:Allocation Product Item
bss.stockallocation.type[1].file.csv.fieldMapping.quotaUOM=COLUMN:Quota UOM
bss.stockallocation.type[1].file.csv.fieldMapping.quotaValue=COLUMN:New Credit Value
bss.stockallocation.type[1].file.csv.fieldMapping.date_effectiveDate=COLUMN:Start Date
bss.stockallocation.type[1].file.csv.fieldMapping.date_expiryDate=COLUMN:End Date
bss.stockallocation.type[1].file.csv.fieldMapping.date_paymentRefundDate=COLUMN:Payment Refund Date
bss.stockallocation.type[1].file.csv.fieldMapping.quotaType=CONSTANT:CREDIT
bss.stockallocation.type[1].file.csv.hasHeader=true
bss.stockallocation.type[1].file.csv.defaultSeparator=,
bss.stockallocation.type[1].file.csv.fieldValidationRegExp=${bss.stockallocation.file.fieldValidationRegExp}

#-------------------------------------------------------------------------------------
# PRODUCT AND VARIANT
#-------------------------------------------------------------------------------------
bss.product.sync.file.fieldValidationRegExp={\
    'SERIAL_CONTROL':'^(Y|N)$' ,\
    'ITEM_ENABLED_FLAG':'^(Y|N)$' ,\
    'PRODUCT_GROUP_TYPE':'^(Physical|Virtual)$' ,\
    'PRICE_START_DATE':'^\\d{4}[-](0[1-9]|1[012])[-](0[1-9]|[12][0-9]|3[01])$' ,\
    'PRICE_END_DATE':'^(\\d{4}[-](0[1-9]|1[012])[-](0[1-9]|[12][0-9]|3[01]))?$' ,\
    'TERTIARY_PRICE':'^\\d+(\\.\\d{1,2})?$' \
}
#constant property represents comma separated list of hybrid product codes
bss.product.type[0].id=Product_And_Variant
bss.product.hybrid-item-codes=
bss.product.type[0].operation=IMPORT_PRODUCT_WITH_VARIANT
bss.product.type[0].allowedFor=ALL
# Default s.type[0]cheduling type (when not provided in the RESP request)
bss.product.type[0].processor.schedType=immediate
# Schedulin.type[0]g time in spring cron format (when scheduling type is 'scheduled')
bss.product.type[0].processor.schedTime=0/20 * * * * ?
bss.product.type[0].processor.schedTypeDelay-sec=20
bss.product.type[0].processor.failOnError=false
bss.product.type[0].processor.chunkSize=10
bss.product.type[0].processor.maxRetryCount=3
#after what.type[0] number of minutes (from the first retry) another retry should be considered
bss.product.type[0].processor.retryDelay=10
bss.product.type[0].file.uploadDescription=product ${bss.product.type[0].id} import file
bss.product.type[0].file.supportedFormats=CSV
bss.product.type[0].file.format=CSV
bss.product.type[0].file.csv.freemarkerTemplate=product_with_variant_import.ftl
bss.product.type[0].file.csv.header=ITEM_CODE,DESCRIPTION,ITEM_TYPE,ITEM_CATEGORY,PRODUCT_GROUP_TYPE,SERIAL_CONTROL,PRICE_START_DATE,PRICE_END_DATE,TERTIARY_PRICE,UOM_CODE,ITEM_SEGMENT5,ITEM_SEGMENT6,ITEM_SEGMENT7,ITEM_SEGMENT8,ITEM_ENABLED_FLAG,ITEM_START_DATE,ITEM_END_DATE,LOT_CONTROL
bss.product.type[0].file.csv.hasHeader=true
bss.product.type[0].file.csv.defaultSeparator=,
bss.product.type[0].file.csv.fieldMapping.code=COLUMN:ITEM_CODE
bss.product.type[0].file.csv.fieldMapping.name=COLUMN:DESCRIPTION
bss.product.type[0].file.csv.fieldMapping.description=COLUMN:DESCRIPTION
bss.product.type[0].file.csv.fieldMapping.categoryName=COLUMN:ITEM_CATEGORY
bss.product.type[0].file.csv.fieldMapping.workflowId=CONSTANT:1
bss.product.type[0].file.csv.fieldMapping.supplierReference=CONSTANT:OPERATOR
bss.product.type[0].file.csv.fieldMapping.supplierId=CONSTANT:1
bss.product.type[0].file.csv.fieldMapping.productType=MULTI_SWITCH:\
<IF>AND(COLUMN:ITEM_CATEGORY=Scratch Card,COLUMN:ITEM_TYPE=RELOAD)<THEN>CONSTANT:hybrid\
<IF>AND(COLUMN:PRODUCT_GROUP_TYPE=Physical,COLUMN:SERIAL_CONTROL=Y)<THEN>CONSTANT:serialised\
<IF>AND(COLUMN:PRODUCT_GROUP_TYPE=Physical,COLUMN:SERIAL_CONTROL=N)<THEN>CONSTANT:non-serialised\
<IF>AND(COLUMN:PRODUCT_GROUP_TYPE=Virtual,COLUMN:ITEM_TYPE=MFS)<THEN>CONSTANT:services\
<IF>AND(COLUMN:PRODUCT_GROUP_TYPE=Virtual,COLUMN:ITEM_TYPE=RELOAD)<THEN>CONSTANT:services\
<IF>AND(COLUMN:PRODUCT_GROUP_TYPE=Virtual,COLUMN:ITEM_TYPE=Service)<THEN>CONSTANT:pure-service\
<IF>AND(COLUMN:PRODUCT_GROUP_TYPE=Virtual,COLUMN:ITEM_TYPE=SERVICE)<THEN>CONSTANT:pure-service\
<DEFAULT>CONSTANT:NA
bss.product.type[0].file.csv.fieldMapping.availableFrom=COLUMN:PRICE_START_DATE
bss.product.type[0].file.csv.fieldMapping.availableUntil=COLUMN:PRICE_END_DATE
bss.product.type[0].file.csv.fieldMapping.status=SWITCH_COLUMN:ITEM_ENABLED_FLAG<CASE>Y<THEN>CONSTANT:available<CASE>N<THEN>CONSTANT:decommissioned
bss.product.type[0].file.csv.fieldMapping.list_variants[0].productSKU=COLUMN:ITEM_CODE
bss.product.type[0].file.csv.fieldMapping.list_variants[0].productVariantDescription=COLUMN:DESCRIPTION
bss.product.type[0].file.csv.fieldMapping.list_variants[0].productVariantName=COLUMN:DESCRIPTION
bss.product.type[0].file.csv.fieldMapping.list_variants[0].status=SWITCH_COLUMN:ITEM_ENABLED_FLAG<CASE>Y<THEN>CONSTANT:available<CASE>N<THEN>CONSTANT:decommissioned
bss.product.type[0].file.csv.fieldMapping.list_variants[0].availableFrom=COLUMN:PRICE_START_DATE
bss.product.type[0].file.csv.fieldMapping.list_variants[0].availableUntil=COLUMN:PRICE_END_DATE
bss.product.type[0].file.csv.fieldMapping.list_variants[0].unitPrice.currency=CONSTANT:BDT
bss.product.type[0].file.csv.fieldMapping.list_variants[0].unitPrice.price=COLUMN:TERTIARY_PRICE
bss.product.type[0].file.csv.fieldMapping.list_variants[0].unitPrice.variablePrice=MULTI_SWITCH:\
<IF>AND(COLUMN:PRODUCT_GROUP_TYPE=Virtual,COLUMN:ITEM_TYPE=MFS)<THEN>CONSTANT:true\
<IF>AND(COLUMN:PRODUCT_GROUP_TYPE=Virtual,COLUMN:ITEM_TYPE=RELOAD)<THEN>CONSTANT:true\
<DEFAULT>CONSTANT:false
bss.product.type[0].file.csv.fieldMapping.list_variants[0].unitOfMeasure.unit=COLUMN:UOM_CODE
bss.product.type[0].file.csv.fieldMapping.list_variants[0].unitOfMeasure.quantity=CONSTANT:1
bss.product.type[0].file.csv.fieldMapping.list_variants[0].list_data[1].dataName=CONSTANT:LOT_CONTROL
bss.product.type[0].file.csv.fieldMapping.list_variants[0].list_data[1].dataValue=SWITCH_COLUMN:LOT_CONTROL<CASE>Y<THEN>CONSTANT:Y<CASE>N<THEN>CONSTANT:N<DEFAULT>CONSTANT:N
bss.product.type[0].file.csv.fieldMapping.list_variants[0].list_data[2].dataName=CONSTANT:ITEM_SEGMENT5
bss.product.type[0].file.csv.fieldMapping.list_variants[0].list_data[2].dataValue=COLUMN:ITEM_SEGMENT5
bss.product.type[0].file.csv.fieldMapping.list_variants[0].list_data[3].dataName=CONSTANT:ITEM_SEGMENT6
bss.product.type[0].file.csv.fieldMapping.list_variants[0].list_data[3].dataValue=COLUMN:ITEM_SEGMENT6
bss.product.type[0].file.csv.fieldMapping.list_variants[0].list_data[4].dataName=CONSTANT:ITEM_SEGMENT7
bss.product.type[0].file.csv.fieldMapping.list_variants[0].list_data[4].dataValue=COLUMN:ITEM_SEGMENT7
bss.product.type[0].file.csv.fieldMapping.list_variants[0].list_data[5].dataName=CONSTANT:ITEM_SEGMENT8
bss.product.type[0].file.csv.fieldMapping.list_variants[0].list_data[5].dataValue=COLUMN:ITEM_SEGMENT8
bss.product.type[0].file.csv.fieldMapping.list_variants[0].isBundle=CONSTANT:false
bss.product.type[0].file.csv.fieldMapping.list_data[0].dataName=CONSTANT:PRODUCT_GROUP_TYPE
bss.product.type[0].file.csv.fieldMapping.list_data[0].dataValue=COLUMN:PRODUCT_GROUP_TYPE
bss.product.type[0].file.csv.fieldMapping.ancestorCategoryName=COLUMN:ITEM_TYPE
bss.product.type[0].file.csv.fieldValidationRegExp=${bss.product.sync.file.fieldValidationRegExp}

#-------------------------------------------------------------------------------------
# CONTRACTS PRICING LIST
#-------------------------------------------------------------------------------------
bss.contract.defaultAllowedFor=ALL
# Contract Pricing List Import Field Validation RegExp
bss.contract.pricing.list.import.fieldValidationRegExp={ \
'ItemCode':'^[0-9]+$', \
'PrimaryDiscount':'^(\\d+\\.?\\d{0,2})?$', \
'SecondaryDiscount':'^(\\d+\\.?\\d{0,2})?$', \
'ValidFrom':'^((0[1-9]|[12][0-9]|3[01])\/(0[1-9]|1[0-2])\/\\d{4})?$' \
}
bss.contract.type[0].id=contracts_pricing_import
bss.contract.type[0].operation=CONTRACTS_PRICING_IMPORT
bss.contract.type[0].allowedFor=${bss.contract.defaultAllowedFor}
bss.contract.type[0].jobSpecificNotificationEnable=false
bss.contract.type[0].jobSpecificRetryFileMerge=false
# Comma separated list (can be empty). Two batches having the same tag will not be executed at the same time (no overlapping execution)
bss.contract.type[0].processor.exclusiveTags=contract
bss.contract.type[0].processor.schedType=immediate
bss.contract.type[0].processor.schedTime=0/10 * * * * ?
bss.contract.type[0].processor.schedTypeDelay-sec=10
bss.contract.type[0].processor.failOnError=false
bss.contract.type[0].processor.chunkSize=10
bss.contract.type[0].processor.maxRetryCount=3
bss.contract.type[0].processor.retryDelay=10
bss.contract.type[0].file.uploadDescription=contract ${bss.contract.type[0].id} import file
bss.contract.type[0].file.supportedFormats=CSV
bss.contract.type[0].file.format=CSV
bss.contract.type[0].file.csv.freemarkerTemplate=contracts_pricing_list_import.ftl
bss.contract.type[0].file.csv.header=ItemCode,Channel,National,Circle,Region,Cluster,Territory,PrimaryDiscount,SecondaryDiscount,ValidFrom
bss.contract.type[0].file.csv.hasHeader=true
bss.contract.type[0].file.csv.defaultSeparator=,
bss.contract.type[0].file.csv.fieldMapping.itemCode=COLUMN:ItemCode
bss.contract.type[0].file.csv.fieldMapping.validFromDate=COLUMN:ValidFrom
bss.contract.type[0].file.csv.fieldMapping.CHANNEL=COLUMN:Channel
bss.contract.type[0].file.csv.fieldMapping.NATIONAL=COLUMN:National
bss.contract.type[0].file.csv.fieldMapping.CIRCLE=COLUMN:Circle
bss.contract.type[0].file.csv.fieldMapping.REGION=COLUMN:Region
bss.contract.type[0].file.csv.fieldMapping.CLUSTER=COLUMN:Cluster
bss.contract.type[0].file.csv.fieldMapping.TERRITORY=COLUMN:Territory
bss.contract.type[0].file.csv.fieldMapping.Primary=COLUMN:PrimaryDiscount
bss.contract.type[0].file.csv.fieldMapping.Secondary=COLUMN:SecondaryDiscount
bss.contract.type[0].processor.parallelChunkNb=1
bss.contract.type[0].processor.fallbackOnError=true
# Field Validation
bss.contract.type[0].file.csv.fieldValidationRegExp=${bss.contract.pricing.list.import.fieldValidationRegExp}

#-------------------------------------------------------------------------------------
# IDM Region Demarcation
#-------------------------------------------------------------------------------------
bss.demarcation.IDM_region_demarcation.fieldValidationRegExp={\
   'Circle': '^[^:]+:[^:]+$',\
   'Region': '^[^:]+:[^:]+$',\
   'Cluster': '^[^:]+:[^:]+$',\
   'Territory': '^[^:]+:[^:]+$',\
   'Thana': '^[^:]+:[^:]+$'\
}
bss.demarcation.defaultAllowedFor=ALL
bss.demarcation.id=IDM_region_demarcation
#bss.demarcation.label= IDM Region Demarcation
bss.demarcation.operation=IDM_REGION_UPDATE
bss.demarcation.allowedFor=${bss.demarcation.defaultAllowedFor}
bss.demarcation.processor.schedType=immediate
bss.demarcation.preferredLanguage=en
bss.demarcation.processor.schedTime=0 0 1 * * ?
bss.demarcation.processor.schedTypeDelay-sec=60
bss.demarcation.processor.failOnError=false
bss.demarcation.processor.chunkSize=1
bss.demarcation.processor.maxRetryCount=3
bss.demarcation.file.uploadDescription=Region ${bss.demarcation.id} import file
bss.demarcation.file.supportedFormats=CSV
bss.demarcation.file.format=CSV
bss.demarcation.file.csv.freemarkerTemplate=idm_region_update_demarcation.ftl
bss.demarcation.file.csv.header=Circle,Region,Cluster,Territory,Thana
bss.demarcation.file.csv.hasHeader=true
bss.demarcation.file.csv.defaultSeparator=,
bss.demarcation.file.csv.fieldMapping.circle=COLUMN:Circle
bss.demarcation.file.csv.fieldMapping.region=COLUMN:Region
bss.demarcation.file.csv.fieldMapping.cluster=COLUMN:Cluster
bss.demarcation.file.csv.fieldMapping.territory=COLUMN:Territory
bss.demarcation.file.csv.fieldMapping.thana=COLUMN:Thana
bss.demarcation.processor.gatewayErrorsAutomaticRetry=true
bss.demarcation.processor.immediateRetry=true
bss.demarcation.file.csv.fieldValidationRegExp=${bss.demarcation.IDM_region_demarcation.fieldValidationRegExp}


#----------------------------------------------------------------------------------------------------------
# IDM Reseller Area Demarcation
#----------------------------------------------------------------------------------------------------------
bss.demarcation.IDM_Reseller_area_demarcation.fieldValidationRegExp={\
   'ResellerId':'.*' ,\
   'ToBeParent':'.*' ,\
   'RouteAdmin':'.*' \
}
bss.demarcation.type[0].defaultAllowedFor=ALL
bss.demarcation.type[0].id=IDM_reseller_area_demarcation
#bss.demarcation.type[0].label=IDM Reseller Area Demarcation
bss.demarcation.type[0].operation=IDM_RESELLER_AREA
bss.demarcation.type[0].allowedFor=${bss.demarcation.defaultAllowedFor}
bss.demarcation.type[0].processor.schedType=immediate
bss.demarcation.type[0].preferredLanguage=en
bss.demarcation.type[0].processor.schedTime=0 0 1 * * ?
bss.demarcation.type[0].processor.schedTypeDelay-sec=60
bss.demarcation.type[0].processor.failOnError=false
bss.demarcation.type[0].processor.chunkSize=1
bss.demarcation.type[0].processor.gatewayErrorsAutomaticRetry=true
bss.demarcation.type[0].processor.immediateRetry=true
bss.demarcation.type[0].file.uploadDescription=demarcation ${bss.demarcation.type[0].id} import file
bss.demarcation.type[0].file.supportedFormats=CSV
bss.demarcation.type[0].file.format=CSV
bss.demarcation.type[0].file.csv.freemarkerTemplate=idm_reseller_area_demarcation.ftl
bss.demarcation.type[0].file.csv.header=ResellerId,ResellerType,ToBeParent,RouteAdmin,RouteCode,ToBeCircleCode,ToBeRegionCode,ToBeClusterCode,ToBeTerritoryCode,ToBeThanaCode
bss.demarcation.type[0].file.csv.hasHeader=true
bss.demarcation.type[0].file.csv.defaultSeparator=,
bss.demarcation.type[0].file.csv.fieldMapping.resellerId=COLUMN:ResellerId
bss.demarcation.type[0].file.csv.fieldMapping.resellerType=COLUMN:ResellerType
bss.demarcation.type[0].file.csv.fieldMapping.toBeParent=COLUMN:ToBeParent
bss.demarcation.type[0].file.csv.fieldMapping.toBeRouteAdmin=COLUMN:RouteAdmin
bss.demarcation.type[0].file.csv.fieldMapping.toBeRouteCode=COLUMN:RouteCode
bss.demarcation.type[0].file.csv.fieldMapping.toBeCircleCode=COLUMN:ToBeCircleCode
bss.demarcation.type[0].file.csv.fieldMapping.toBeRegionCode=COLUMN:ToBeRegionCode
bss.demarcation.type[0].file.csv.fieldMapping.toBeClusterCode=COLUMN:ToBeClusterCode
bss.demarcation.type[0].file.csv.fieldMapping.toBeTerritoryCode=COLUMN:ToBeTerritoryCode
bss.demarcation.type[0].file.csv.fieldMapping.toBeThanaCode=COLUMN:ToBeThanaCode
#-------------------------------------------------------------------------------------
# Batch configuration to import Resellers(Employees) synced from Gp hr portal
#-------------------------------------------------------------------------------------
bss.reseller.type[0].id=Users_ONBOARD_EMPLOYEES_Generic
bss.reseller.type[0].allowedFor=${bss.reseller.defaultAllowedFor}
bss.reseller.type[0].processor.schedType=immediate
bss.reseller.type[0].processor.schedTime=0 */2 * ? * *
bss.reseller.type[0].processor.schedTypeDelay-sec=30
bss.reseller.type[0].processor.failOnError=false
bss.reseller.type[0].processor.chunkSize=10
bss.reseller.type[0].file.uploadDescription=Reseller ${bss.reseller.type[0].id} import file
bss.reseller.type[0].file.supportedFormats=CSV
bss.reseller.type[0].file.format=CSV
bss.reseller.type[0].file.csv.freemarkerTemplate=admin_import.ftl
bss.reseller.type[0].file.csv.header=Reseller_Name,Reseller_MSISDN,Parent_Reseller_Id,Reseller_Email_User,Reseller_Email_User_RoleId,Reseller_Email_User_RoleName,Reseller_Type,Status,Is_Auto_Transfer
bss.reseller.type[0].file.csv.hasHeader=true
bss.reseller.type[0].file.csv.defaultSeparator=,
bss.reseller.type[0].file.csv.fieldMapping.resellerName=COLUMN:Reseller_Name
bss.reseller.type[0].file.csv.fieldMapping.resellerMSISDN=COLUMN:Reseller_MSISDN
bss.reseller.type[0].file.csv.fieldMapping.resellerTypeId=COLUMN:Reseller_Type
bss.reseller.type[0].file.csv.fieldMapping.parentResellerId=COLUMN:Parent_Reseller_Id
bss.reseller.type[0].file.csv.fieldMapping.status=MAP_COLUMN:enabledToStatus:Status
bss.reseller.type[0].file.csv.fieldMapping.isAutoTransfer=COLUMN:Is_Auto_Transfer
bss.reseller.type[0].file.csv.fieldMapping.extraParam_isSyncFromHrPortal=CONSTANT:true
#bss.reseller.type[0].file.csv.fieldMapping.extraParam_domainName=CONSTANT:OPERATOR
bss.reseller.type[0].file.csv.fieldMapping.extraParam_domainCode=CONSTANT:OPT
bss.reseller.type[0].file.csv.fieldMapping.extraParam_name=COLUMN:Reseller_Name
bss.reseller.type[0].file.csv.fieldMapping.user_userId=COLUMN:Reseller_Email_User
bss.reseller.type[0].file.csv.fieldMapping.user_roleId=COLUMN:Reseller_Email_User_RoleId
bss.reseller.type[0].file.csv.fieldMapping.user_roleName=COLUMN:Reseller_Email_User_RoleName
bss.reseller.type[0].file.csv.fieldMapping.user_phone=COLUMN:Reseller_MSISDN
bss.reseller.type[0].file.csv.fieldMapping.user_email=COLUMN:Reseller_Email_User
bss.reseller.type[0].file.csv.fieldMapping.address_email=COLUMN:Reseller_Email_User

#-------------------------------------------------------------------------------------
# Deactivate Resellers
#-------------------------------------------------------------------------------------
bss.reseller.type[1].id=Reseller_Deactivate
bss.reseller.type[1].operation=DEACTIVATE
bss.reseller.type[1].allowedFor=${bss.reseller.defaultAllowedFor}
bss.reseller.type[1].processor.schedType=immediate
# Scheduling spring cron format (when scheduling type is 'scheduled')
bss.reseller.type[1].processor.schedTime=0 */10 * ? * *
bss.reseller.type[1].processor.schedTypeDelay-sec=60
bss.reseller.type[1].processor.failOnError=true
### Keep the chunkSize=10 because currently DMS support this with 10 or less
bss.reseller.type[1].processor.chunkSize=10
bss.reseller.type[1].file.uploadedBy=rcvdReseller
bss.reseller.type[1].file.uploadDescription=Deactivate Reseller ${bss.reseller.type[1].id} import file
bss.reseller.type[1].file.supportedFormats=CSV,JSON
bss.reseller.type[1].file.format=CSV
bss.reseller.type[1].file.csv.freemarkerTemplate=reseller_deactivate.ftl
bss.reseller.type[1].file.csv.header=Reseller_Id,Deboard_Reason
bss.reseller.type[1].file.csv.hasHeader=true
bss.reseller.type[1].file.csv.defaultSeparator=,
bss.reseller.type[1].file.csv.fieldMapping.resellerId=COLUMN:Reseller_Id
bss.reseller.type[1].file.csv.fieldMapping.reason=COLUMN:Deboard_Reason
bss.reseller.type[1].file.csv.fieldMapping.status=CONSTANT:Deactivated
bss.reseller.type[1].file.csv.fieldMapping.isAutoTransfer=CONSTANT:1
bss.reseller.type[1].file.csv.fieldValidationRegExp={\
'Reseller_Id': '[a-zA-Z0-9][a-zA-Z0-9_-]*',\
'Deboard_Reason': '^(?!\s*$).+'\
}

#-------------------------------------------------------------------------------------
# Update Reseller User
#-------------------------------------------------------------------------------------
bss.reseller.type[2].defaultAllowedFor=ALL
bss.reseller.type[2].id=Reseller_User_Update
bss.reseller.type[2].operation=UPDATE
bss.reseller.type[2].allowedFor=${bss.reseller.type[2].defaultAllowedFor}
# Default scheduling type (when not provided in the RESP request)
bss.reseller.type[2].processor.schedType=immediate
# Scheduling time in spring cron format (when scheduling type is 'scheduled')
bss.reseller.type[2].processor.schedTime=0/30 * * * * ?
bss.reseller.type[2].processor.schedTypeDelay-sec=30
bss.reseller.type[2].processor.failOnError=false
bss.reseller.type[2].processor.chunkSize=10
# Number of chunks executed in parallel
bss.reseller.type[2].processor.maxRetryCount=3
#after what number of minutes (from the first retry) another retry should be considered
bss.reseller.type[2].processor.retryDelay=5
bss.reseller.type[2].file.uploadDescription=Reseller ${bss.reseller.type[2].id} import file
bss.reseller.type[2].file.supportedFormats=CSV,JSON
bss.reseller.type[2].file.format=CSV
bss.reseller.type[2].file.csv.hasHeader=true
bss.reseller.type[2].file.csv.defaultSeparator=,
bss.reseller.type[2].file.csv.freemarkerTemplate=reseller_user_update.ftl
bss.reseller.type[2].file.csv.header=RESELLER_ID,USER_ID,PASSWORD
bss.reseller.type[2].file.csv.fieldMapping.resellerId=COLUMN:RESELLER_ID
bss.reseller.type[2].file.csv.fieldMapping.user_userId=COLUMN:USER_ID
bss.reseller.type[2].file.csv.fieldMapping.user_password=COLUMN:PASSWORD

#-------------------------------------------------------------------------------------
# Batch Inventory Type Serialized Import
#-------------------------------------------------------------------------------------
bss.inventory.type[2].id=Serialized_Inventory_Import
bss.inventory.type[2].operation=SERIALIZED_INVENTORY_IMPORT
bss.inventory.type[2].allowedFor=${bss.inventory.defaultAllowedFor}
bss.inventory.type[2].processor.schedType=scheduled
# Scheduling time in spring cron format (when scheduling type is 'scheduled')
bss.inventory.type[2].processor.schedTime=0 1 * * * ?
bss.inventory.type[2].processor.schedTypeDelay-sec=30
bss.inventory.type[2].processor.failOnError=true
bss.inventory.type[2].processor.chunkSize=100
# Number of chunks executed in parallel
# bss.inventory.type[2].processor.parallelChunkNb=10
bss.inventory.type[2].file.uploadDescription=Inventory ${bss.inventory.type[2].id} import file
bss.inventory.type[2].file.supportedFormats=CSV
bss.inventory.type[2].file.format=CSV
bss.inventory.type[2].file.csv.freemarkerTemplate=inventory_import.ftl
bss.inventory.type[2].file.csv.header=Product SKU,Serial,Status,Owner,Location
bss.inventory.type[2].file.csv.hasHeader=true
bss.inventory.type[2].file.csv.defaultSeparator=,
bss.inventory.type[2].file.csv.fieldMapping.productSKU=COLUMN:Product SKU
bss.inventory.type[2].file.csv.fieldMapping.serialNo=COLUMN:Serial
bss.inventory.type[2].file.csv.fieldMapping.state=COLUMN:Status
bss.inventory.type[2].file.csv.fieldMapping.owner=COLUMN:Owner
bss.inventory.type[2].file.csv.fieldMapping.locationId=COLUMN:Location


#-------------------------------------------------------------------------------------
# Batch Inventory Type Non Serialized Import
#-------------------------------------------------------------------------------------
#### Non serialized inventory Import Field Validation RegExp
bss.inventory.non.serial.import.fieldValidationRegExp={ \
'Quantity':'^[0-9]+$' \
}
bss.inventory.type[3].id=Non_Serialized_Inventory_Import
bss.inventory.type[3].operation=NON_SERIALIZED_INVENTORY_IMPORT
bss.inventory.type[3].allowedFor=${bss.inventory.defaultAllowedFor}
bss.inventory.type[3].processor.schedType=scheduled
# Scheduling time in spring cron format (when scheduling type is 'scheduled')
bss.inventory.type[3].processor.schedTime=0 1 * * * ?
bss.inventory.type[3].processor.schedTypeDelay-sec=30
bss.inventory.type[3].processor.failOnError=true
bss.inventory.type[3].processor.chunkSize=100
# Number of chunks executed in parallel
# bss.inventory.type[3].processor.parallelChunkNb=10
bss.inventory.type[3].file.uploadDescription=Inventory ${bss.inventory.type[3].id} import file
bss.inventory.type[3].file.supportedFormats=CSV
bss.inventory.type[3].file.format=CSV
bss.inventory.type[3].file.csv.freemarkerTemplate=inventory_import.ftl
bss.inventory.type[3].file.csv.header=Product SKU,Quantity,Status,Owner,Location
bss.inventory.type[3].file.csv.hasHeader=true
bss.inventory.type[3].file.csv.defaultSeparator=,
bss.inventory.type[3].file.csv.fieldMapping.productSKU=COLUMN:Product SKU
bss.inventory.type[3].file.csv.fieldMapping.quantity=COLUMN:Quantity
bss.inventory.type[3].file.csv.fieldMapping.state=COLUMN:Status
bss.inventory.type[3].file.csv.fieldMapping.owner=COLUMN:Owner
bss.inventory.type[3].file.csv.fieldMapping.locationId=COLUMN:Location
# Field Validation
bss.inventory.type[3].file.csv.fieldValidationRegExp=${bss.inventory.non.serial.import.fieldValidationRegExp}
